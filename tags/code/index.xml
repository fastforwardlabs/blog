<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>code on Blog</title>
    <link>https://blog.fastforwardlabs.com/tags/code.html</link>
    <description>Recent content in code on Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 23 Nov 2016 18:36:58 +0000</lastBuildDate>
    
    <atom:link href="https://blog.fastforwardlabs.com/tags/code/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Probabilistic Data Structure Showdown: Cuckoo Filters vs. Bloom Filters</title>
       
      <link>https://blog.fastforwardlabs.com/2016/11/23/probabilistic-data-structure-showdown-cuckoo-filters-vs.-bloom-filters.html</link>
      
      <pubDate>Wed, 23 Nov 2016 18:36:58 +0000</pubDate>
      
      <guid>https://blog.fastforwardlabs.com/2016/11/23/probabilistic-data-structure-showdown-cuckoo-filters-vs.-bloom-filters.html</guid>
      <description>Probabilistic data structures store data compactly with low memory and provide approximate answers to queries about stored data. They are designed to answer queries in a space-efficient manner, which can mean sacrificing accuracy. However, they typically provide guarantees and bounds on error rates depending on specifications of the data structure in question. Because they provide low memory footprints, probabilisitic data structures are particularly useful ink streaming and low power settings.</description>
      <imglink>/tumblr_files/pmrs-test.png</imglink>
    </item>
    
    <item>
      <title>Exploring Deep Learning on Satellite Data</title>
       
      <link>https://blog.fastforwardlabs.com/2016/08/26/exploring-deep-learning-on-satellite-data.html</link>
      
      <pubDate>Fri, 26 Aug 2016 17:43:24 +0000</pubDate>
      
      <guid>https://blog.fastforwardlabs.com/2016/08/26/exploring-deep-learning-on-satellite-data.html</guid>
      <description>This is a guest post featuring a project Patrick Doupe, now a Senior Data Analyst at Icahn School of Medicine at Mount Sinai, completed as a fellow in the Insight Data Science program. In our partnership with Insight, we occassionally advise fellows on month-long projects and how to build a career in data science. Machines are getting better at identifying objects in images. These technologies are used to do more than organise your photos or chat your family and friends with snappy augmented pictures and movies.</description>
      <imglink>http://fastforwardlabs.github.io/blog-images/geo/empty_satellite_image.png</imglink>
    </item>
    
    <item>
      <title>Under the Hood of the Variational Autoencoder (in Prose and Code)</title>
       
      <link>https://blog.fastforwardlabs.com/2016/08/22/under-the-hood-of-the-variational-autoencoder-in-prose-and-code.html</link>
      
      <pubDate>Mon, 22 Aug 2016 18:02:08 +0000</pubDate>
      
      <guid>https://blog.fastforwardlabs.com/2016/08/22/under-the-hood-of-the-variational-autoencoder-in-prose-and-code.html</guid>
      <description>&lt;h5 id=&#34;the-a-hrefhttpsarxivorgabs13126114variationala-a-hrefhttpsarxivorgabs14014082autoencodera-vae-neatly-synthesizes-unsupervised-deep-learning-and-variational-bayesian-methods-into-one-sleek-package-in-a-hrefhttpblogfastforwardlabscom20160812introducing-variational-autoencoders-in-prose-andhtmlpart-ia-of-this-series-we-introduced-the-theory-and-intuition-behind-the-vae-an-exciting-development-in-machine-learning-for-combined-generative-modeling-and-inferencea-hrefhttpshakirmcomslidesdlsummerschool_aug2016_compresspdfmachines-that-imagine-and-reasona&#34;&gt;The &lt;a href=&#34;https://arxiv.org/abs/1312.6114&#34;&gt;Variational&lt;/a&gt; &lt;a href=&#34;https://arxiv.org/abs/1401.4082&#34;&gt;Autoencoder&lt;/a&gt; (VAE) neatly synthesizes unsupervised deep learning and variational Bayesian methods into one sleek package. In &lt;a href=&#34;http://blog.fastforwardlabs.com/2016/08/12/introducing-variational-autoencoders-in-prose-and.html&#34;&gt;Part I&lt;/a&gt; of this series, we introduced the theory and intuition behind the VAE, an exciting development in machine learning for combined generative modeling and inference—&lt;a href=&#34;http://shakirm.com/slides/DLSummerSchool_Aug2016_compress.pdf&#34;&gt;“machines that imagine and reason.”&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;To recap: VAEs put a probabilistic spin on the basic autoencoder paradigm—treating their inputs, hidden representations, and reconstructed outputs as probabilistic random variables within a directed graphical model. With this &lt;a href=&#34;https://xkcd.com/1236/&#34;&gt;Bayesian&lt;/a&gt; perspective, the encoder becomes a variational &lt;em&gt;inference network&lt;/em&gt;, mapping observed inputs to (approximate) posterior distributions over latent space, and the decoder becomes a &lt;em&gt;generative network&lt;/em&gt;, capable of mapping arbitrary latent coordinates back to distributions over the original data space.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://fastforwardlabs.github.io/blog-images/miriam/imgs_code/vae.4.png&#34; title=&#34;A variational autoencoder&#34; style=&#34;width:80.0%&#34;/&gt;&lt;/div&gt;
&lt;p&gt;The beauty of this setup is that we can take a principled Bayesian approach toward building systems with a rich internal “mental model” of the observed world, all by training a single, cleverly-designed deep neural network.&lt;/p&gt;
&lt;p&gt;These benefits derive from an enriched understanding of data as merely the tip of the iceberg—the observed result of an underlying causative probabilistic process.&lt;/p&gt;
&lt;p&gt;The power of the resulting model is captured by Feynman’s famous &lt;a href=&#34;http://archives-dc.library.caltech.edu/islandora/object/ct1:483&#34;&gt;chalkboard quote&lt;/a&gt;: “What I cannot create, I do not understand.” When trained on MNIST handwritten digits, our VAE model can parse the information spread thinly over the high-dimensional observed world of pixels, and condense the most meaningful features into a structured distribution over reduced latent dimensions.&lt;/p&gt;
&lt;p&gt;Having recovered the latent manifold and assigned it a coordinate system, it becomes trivial to walk from one point to another along the manifold, creatively generating realistic digits all the while:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://fastforwardlabs.github.io/blog-images/miriam/imgs_code/160816_1754_reloaded_latent_784_500_500_50_round_65536_morph_4730816952.gif&#34; title=&#34;Generatively morphing digits&#34;/&gt;&lt;/div&gt;
&lt;p&gt;In this post, we’ll take a look under the hood at the math and technical details that allow us to optimize the VAE model we sketched in &lt;a href=&#34;http://fastforwardlabs.github.io/2016/08/12/introducing-variational-autoencoders-in-prose-and.html&#34;&gt;Part I&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Along the way, we’ll show how to implement a VAE in &lt;a href=&#34;http://tensorflow.org/&#34;&gt;TensorFlow&lt;/a&gt;—a library for efficient numerical computation using data flow graphs, with key features like &lt;a href=&#34;http://alexey.radul.name/ideas/2013/introduction-to-automatic-differentiation/&#34;&gt;automatic differentiation&lt;/a&gt; and parallelizability (across clusters, CPUs, GPUs…and &lt;a href=&#34;https://cloudplatform.googleblog.com/2016/05/Google-supercharges-machine-learning-tasks-with-custom-chip.html&#34;&gt;TPUs&lt;/a&gt; if you’re lucky). You can find (and tinker with!) the full implementation &lt;a href=&#34;https://github.com/fastforwardlabs/vae-tf/tree/master&#34;&gt;here&lt;/a&gt;, along with a couple &lt;a href=&#34;https://github.com/fastforwardlabs/vae-tf/tree/master/out&#34;&gt;pre-trained models&lt;/a&gt;.&lt;/p&gt;</description>
      <imglink>http://fastforwardlabs.github.io/blog-images/miriam/imgs_code/160816_1754_reloaded_latent_784_500_500_50_round_65536_morph_4730816952.gif</imglink>
    </item>
    
    <item>
      <title>Introducing Variational Autoencoders (in Prose and Code)</title>
       
      <link>https://blog.fastforwardlabs.com/2016/08/12/introducing-variational-autoencoders-in-prose-and-code.html</link>
      
      <pubDate>Fri, 12 Aug 2016 17:09:50 +0000</pubDate>
      
      <guid>https://blog.fastforwardlabs.com/2016/08/12/introducing-variational-autoencoders-in-prose-and-code.html</guid>
      <description>Effective machine learning means building expressive models that sift out signal from noise—that simplify the complexity of real-world data, yet accurately intuit and capture its subtle underlying patterns.
Whatever the downstream application, a primary challenge often boils down to this: How do we represent, or even synthesize, complex data in the context of a tractable model?
This challenge is compounded when working in a limited data setting—especially when samples are in the form of richly-structured, high-dimensional observations like natural images, audio waveforms, or gene expression data.</description>
      <imglink>http://fastforwardlabs.github.io/blog-images/miriam/160727_1340_explore.gray_del11_492x490.slower40.gif</imglink>
    </item>
    
    <item>
      <title>Probabilistic Programming for Anomaly Detection</title>
       
      <link>https://blog.fastforwardlabs.com/2016/05/03/probabilistic-programming-for-anomaly-detection.html</link>
      
      <pubDate>Tue, 03 May 2016 14:51:14 +0000</pubDate>
      
      <guid>https://blog.fastforwardlabs.com/2016/05/03/probabilistic-programming-for-anomaly-detection.html</guid>
      <description>The Fast Forward Labs research team is developing our next prototype, which will demonstrate an application of probabilistic programming. Probabilistic programming languages are a set of high-level languages that lower the barrier to entry for Bayesian data analysis.
Bayesian data analysis is often seen as the best approach to machine learning. Models derived by this process are highly interpretable, in contrast to other modern models like neural networks and support vector machines.</description>
      <imglink>http://68.media.tumblr.com/1d842739c4ecb115ce586049dd552f48/tumblr_inline_o6kjvaPgBs1ta78fg_540.jpg</imglink>
    </item>
    
    <item>
      <title>&#34;Hello world&#34; in Keras (or, Scikit-learn versus Keras)</title>
       
      <link>https://blog.fastforwardlabs.com/2016/02/24/hello-world-in-keras-or-scikit-learn-versus-keras.html</link>
      
      <pubDate>Wed, 24 Feb 2016 18:58:10 +0000</pubDate>
      
      <guid>https://blog.fastforwardlabs.com/2016/02/24/hello-world-in-keras-or-scikit-learn-versus-keras.html</guid>
      <description>This article is available as a notebook on Github. Please refer to that notebook for a more detailed discussion and code fixes and updates. Despite all the recent excitement around deep learning, neural networks have a reputation among non-specialists as complicated to build and difficult to interpret.
And while interpretability remains an issue, there are now high-level neural network libraries that enable developers to quickly build neural network models without worrying about the numerical details of floating point operations and linear algebra.</description>
      <imglink>http://68.media.tumblr.com/a4cf05aa664f57b54fe5021ce966f5d6/tumblr_inline_o30qnzlyxi1qcg73w_540.png</imglink>
    </item>
    
    <item>
      <title>Hello Deep Learning</title>
       
      <link>https://blog.fastforwardlabs.com/2015/10/26/hello-deep-learning.html</link>
      
      <pubDate>Mon, 26 Oct 2015 16:20:07 +0000</pubDate>
      
      <guid>https://blog.fastforwardlabs.com/2015/10/26/hello-deep-learning.html</guid>
      <description>Deep learning is a hot and fascinating research area, particularly when applied to classifying images. While researching the Fast Forward Labs Deep Learning: Image Analysis report, we played with a lot of very cool technology. In this blog post, we offer a guide to getting started with deep learning by using APIs from some of the most interesting deep-learning-as-a-service startups.
These APIs accept images and/or video, and quickly classify objects, ideas, and items shown in the images and video.</description>
      <imglink>http://fastforwardlabs.github.io/report_images/ff03/neural_net_overview.png</imglink>
    </item>
    
    <item>
      <title>How do neural networks learn?</title>
       
      <link>https://blog.fastforwardlabs.com/2015/09/24/how-do-neural-networks-learn.html</link>
      
      <pubDate>Thu, 24 Sep 2015 18:56:09 +0000</pubDate>
      
      <guid>https://blog.fastforwardlabs.com/2015/09/24/how-do-neural-networks-learn.html</guid>
      <description>Neural networks are generating a lot of excitement, as they are quickly proving to be a promising and practical form of machine intelligence. At Fast Forward Labs, we just finished a project researching and building systems that use neural networks for image analysis, as shown in our toy applicationPictograph. Our companion deep learning report explains this technology in depth and explores applications and opportunities across industries.
As we built Pictograph, we came to appreciate just how challenging it is to understand how neural networks work.</description>
      <imglink>http://68.media.tumblr.com/402a5e41ab09be86b8c43ce7f1e147a0/tumblr_inline_nv72twppMF1ta78fg_540.png</imglink>
    </item>
    
    <item>
      <title>Designing the Tech Graph</title>
       
      <link>https://blog.fastforwardlabs.com/2015/05/19/designing-the-tech-graph.html</link>
      
      <pubDate>Tue, 19 May 2015 16:25:01 +0000</pubDate>
      
      <guid>https://blog.fastforwardlabs.com/2015/05/19/designing-the-tech-graph.html</guid>
      <description>We launched a redesign of the Fast Forward Labs website today. There are lots of parts of the design I’d like to write someday about but for this post I want to focus on the thinking behind the “Tech Graph” force-directed graph display in the Intro section.
Dramatizing Information Work The response I want the intro section to provoke is something like: “Wow, there is some really interesting work being done here that I would like to be involved with it.</description>
      <imglink>http://i.imgur.com/bJjtxok.png</imglink>
    </item>
    
    <item>
      <title>Bytecode Hacking for Great Justice</title>
       
      <link>https://blog.fastforwardlabs.com/2015/04/23/bytecode-hacking-for-great-justice.html</link>
      
      <pubDate>Thu, 23 Apr 2015 15:16:56 +0000</pubDate>
      
      <guid>https://blog.fastforwardlabs.com/2015/04/23/bytecode-hacking-for-great-justice.html</guid>
      <description>DO NOT TRY THIS AT HOME! NO PYTHONS WERE HURT IN THE CREATION OF THIS BLOG POST!
Check out the code at code at github.com/mynameisfiber/pytailcall
As an exercise into learning more about python 2.7 bytecode, I wanted to implement the thing that pythonistas love to hate - tail call optimization! This isn&amp;rsquo;t novel at all, but I chose to implement this only using the standard library so that I could understand more about generating and modifying bytecode.</description>
      <imglink>http://i.imgur.com/OodCK0c.png</imglink>
    </item>
    
  </channel>
</rss>
