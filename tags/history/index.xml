<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>history on Blog</title>
    <link>https://blog.fastforwardlabs.com/tags/history.html</link>
    <description>Recent content in history on Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 25 Mar 2016 16:25:43 +0000</lastBuildDate>
    
    <atom:link href="https://blog.fastforwardlabs.com/tags/history/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>H.P. Luhn and the Heuristic Value of Simplicity</title>
       
      <link>https://blog.fastforwardlabs.com/2016/03/25/h.p.-luhn-and-the-heuristic-value-of-simplicity.html</link>
      
      <pubDate>Fri, 25 Mar 2016 16:25:43 +0000</pubDate>
      
      <guid>https://blog.fastforwardlabs.com/2016/03/25/h.p.-luhn-and-the-heuristic-value-of-simplicity.html</guid>
      <description>&lt;figure data-orig-width=&#34;600&#34; data-orig-height=&#34;385&#34; class=&#34;tmblr-full&#34;&gt;&lt;img src=&#34;http://68.media.tumblr.com/8ad092dc44ae1ad68bad697a55274b30/tumblr_inline_o4lon7By6N1ta78fg_540.gif&#34; alt=&#34;image&#34; data-orig-width=&#34;600&#34; data-orig-height=&#34;385&#34;/&gt;&lt;/figure&gt;&lt;p&gt;The Fast Forward Labs team is putting final touches on our &lt;i&gt;Summarization &lt;/i&gt;research, which explains approaches to making text quantifiable and computable. Stay tuned for a series of resources on the topic, including an online talk May 24 where we’ll cover technical details and survey use cases for financial services, media, and professional services with &lt;a href=&#34;http://www.agolo.com/&#34;&gt;Agolo&lt;/a&gt;. Sign up &lt;a href=&#34;https://textsummarizationwebinar.splashthat.com/&#34;&gt;here&lt;/a&gt;! &lt;br/&gt;&lt;/p&gt;&lt;p&gt;In writing our reports, we try not only to inform readers about the libraries, math, and techniques they can use to put a system into production today, but also the lessons they can learn from historical approaches to a given topic. Turning a retrospective eye towards past work can be particularly helpful when using an algorithm like a &lt;a href=&#34;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&#34;&gt;recurrent neural network&lt;/a&gt;. That’s because neural networks are notoriously hard to interpret: feature engineering is left to the algorithm, and involves a &lt;a href=&#34;http://blog.fastforwardlabs.com/2015/09/24/how-do-neural-networks-learn.html&#34;&gt;complex interplay&lt;/a&gt; between the weight of individual computing nodes and the connections that link them together. In the face of this complexity, it can be helpful to keep former, more simple techniques in mind as a heuristic guide - or model - to shape our intuition about how contemporary algorithms work. &lt;/p&gt;&lt;p&gt;For example, we found that &lt;a href=&#34;https://en.wikipedia.org/wiki/Hans_Peter_Luhn&#34;&gt;H.P. Luhn&lt;/a&gt;’s 1958 paper &lt;i&gt;&lt;a href=&#34;http://courses.ischool.berkeley.edu/i256/f06/papers/luhn58.pdf&#34;&gt;The Automatic Creation of Literary Abstracts&lt;/a&gt; &lt;/i&gt;provided a simple heuristic to help wrap our heads around the basic steps that go into probabilistic models for summarizing text. (For those interested in history, Luhn also wrote &lt;a href=&#34;http://altaplana.com/ibmrd0204H.pdf&#34;&gt;a paper about business intelligence&lt;/a&gt; in 1958 that feels like it could have been written today, as it highlights the growing need to automate information retrieval to manage an unwieldy amount of information.) Our design lead, &lt;a href=&#34;https://twitter.com/GrantCuster&#34;&gt;Grant Custer&lt;/a&gt;, designed a prototype you can play with to walk through Luhn’s method. &lt;/p&gt;&lt;p&gt;&lt;a href=&#34;http://fastforwardlabs.github.io/luhn/&#34;&gt;Here’s the link&lt;/a&gt; to access the live demo. Feel free to use the suggested text, or to play around your own (and share results on Twitter!). &lt;br/&gt;&lt;/p&gt;</description>
      <imglink>http://68.media.tumblr.com/8ad092dc44ae1ad68bad697a55274b30/tumblr_inline_o4lon7By6N1ta78fg_540.gif</imglink>
    </item>
    
    <item>
      <title>What History Teaches Us About Data Science</title>
       
      <link>https://blog.fastforwardlabs.com/2016/02/03/what-history-teaches-us-about-data-science.html</link>
      
      <pubDate>Wed, 03 Feb 2016 22:05:44 +0000</pubDate>
      
      <guid>https://blog.fastforwardlabs.com/2016/02/03/what-history-teaches-us-about-data-science.html</guid>
      <description>The FFL team at the New York Historical Society&amp;rsquo;s Silicon City exhibit  Study the past if you would define the future. — Confucius
 Until April 17, 2016, the New York Historical Society is featuring an exhibition called Silicon City: Computer History Made in New York. The Fast Forward Labs team took a field trip to the museum back in December to augment our perspective on our current machine intelligence research (and, of course, to geek out and have fun).</description>
      <imglink>http://68.media.tumblr.com/45c6f3016da356bf6dc765883e601b93/tumblr_inline_o1zrwfo9mf1ta78fg_540.jpg</imglink>
    </item>
    
  </channel>
</rss>
