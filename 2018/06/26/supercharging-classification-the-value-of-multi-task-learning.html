<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />
    
<title>Supercharging Classification - The Value of Multi-task Learning</title>
<meta property="og:title" content="Supercharging Classification - The Value of Multi-task Learning">
<meta property="description" content="Today&rsquo;s machines can identify objects in photographs, predict loan repayments or defaults, write short summaries of long articles, or recommend movies you may like. Up until now, machines have achieved mastery through laser-like focus; most machine learning algorithms today train models to master one task, and one task only. We are excited to introduce multi-task learning in our upcoming webinar, report, and prototype. Multi-task learning is an approach to machine learning that goes beyond single-task approaches and supercharges classification by allowing algorithms to master more than one task at once and in parallel.">
<meta property="og:description" content="Today&rsquo;s machines can identify objects in photographs, predict loan repayments or defaults, write short summaries of long articles, or recommend movies you may like. Up until now, machines have achieved mastery through laser-like focus; most machine learning algorithms today train models to master one task, and one task only. We are excited to introduce multi-task learning in our upcoming webinar, report, and prototype. Multi-task learning is an approach to machine learning that goes beyond single-task approaches and supercharges classification by allowing algorithms to master more than one task at once and in parallel.">
<meta property="og:image" content="https://blog.fastforwardlabs.com/images/2018/06/02_03-1530032857031.png">
<meta property="og:url" content="https://blog.fastforwardlabs.com/2018/06/26/supercharging-classification-the-value-of-multi-task-learning.html">
<meta property="twitter:card" content="summary_large_image">

    <link rel="stylesheet" type="text/css" href="/style.css" />
    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-53030428-5', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

  </head>
  <body>
      <div class="container">
        <div class="spacer"></div>
        <div style="height: 2.5rem; padding-top: 0.35rem;">
          <a target="_blank" href="https://www.cloudera.com/products/fast-forward-labs-research.html">
            <img style="height: 2rem;" src="/images/cloudera-fast-forward-logo.png" />
          </a>
        </div>
        <div class="spacer"></div>
      </div>
      <main id="main">
        
<div class="container">
  <div>
    <h3 class="clear"><a href="/">Blog</a></h3>
  </div>
  <div class="spacer"></div>
  <div class="post">
    <h5 class="clear">
      <span>Jun 26, 2018</span> &middot;
      <span style="text-transform: capitalize;">
        post
      </span>
    </h5>
    <h1>Supercharging Classification - The Value of Multi-task Learning</h1>
    <p>Today&rsquo;s machines can identify objects in photographs, predict loan repayments or
defaults, write short summaries of long articles, or recommend movies you may
like. Up until now, machines have achieved mastery through laser-like focus; most
machine learning algorithms today train models to master one task, and one task only.
We are excited to introduce <strong>multi-task learning</strong> in our upcoming
<a href="https://www.cloudera.com/content/dam/www/marketing/resources/webinars/Multi-task-learning-recorded-webinar.png.landing.html">webinar</a>,
report, and prototype. Multi-task learning is an approach to machine learning
that goes beyond single-task approaches and supercharges classification by
allowing algorithms to master more than one task at once and in parallel.</p>
<p>The basic idea in multi-task learning is that learning several tasks at once
allows models to benefit from relationships between tasks for improved
performance (alongside other benefits we will cover in the webinar and report). At
an intuitive level, this makes sense. A child learning to read is supported by
learning the shapes of letters and learning how to talk. Similarly, a machine
learning model that is learning to understand language benefits from learning
to identify parts of speech while concurrently learning to identify the
semantic role words play in a sentence.</p>
<p><img src="/images/2018/06/02_03-1530032857031.png" alt=""></p>
<h5 id="multi-task-learning-can-improve-the-prediction-of-two-variables-eg-risk-factor-and-white-blood-cell-countat-the-same-time-that-it-improves-overall-performance">Multi-task Learning can improve the prediction of two variables (e.g. &ldquo;risk factor&rdquo; and &ldquo;white blood cell count&rdquo;)at the same time that it improves overall performance.</h5>
<p>Recently, multi-task learning was shown to improve the prediction of diabetic
retinopathy. A team at <a href="https://ai.google/research/teams/brain">Google Brain</a>,
using ophthalmology databases that store thousands of retinal images, was
able to train a <a href="https://arxiv.org/abs/1708.09843">multi-task neural network</a>
to predict a variety of diagnostic attributes, from trivially easy (&lsquo;left&rsquo; or
&lsquo;right&rsquo; eye) to surprisingly difficult (&lsquo;male&rsquo; or &lsquo;female&rsquo; patient), in addition
to the main task: the prediction of diabetic retinopathy. The outcome? Even
trained ophthalmologists were surprised by the network&rsquo;s performance. The
prediction of the diabetic retinopathy task benefited from the addition of other tasks,
showing that seemingly less important tasks can be added to a
single-task algorithm (turning it into a multi-task algorithm) to support a
primary, difficult task.</p>
<p>Similarly,
<a href="https://arxiv.org/abs/1703.07771">researchers</a> have improved the ability of a model trained on hospital records to predict patient
mortality by adding length-of-stay as a second target variable.
Agronomists have improved soil chemistry detection by training a
<a href="http://www.mdpi.com/2072-4292/9/11/1099">model</a> to learn multiple chemical
signatures simultaneously. <a href="http://bons.ai">Roboticists</a>, in a twist on concept
learning, have trained a robotic arm  with MTL to satisfy both intermediate and
end goals concurrently in a way that better supports that end goal.
<a href="http://www.enlitic.com">Radiologists</a> have used images labeled as &lsquo;normal&rsquo; or
&lsquo;abnormal&rsquo; alongside pixel-level labels for regions-of-interest that show the
location of the abnormality to improve disease detection from imagery. And,
under the hood, <a href="https://www.nature.com/articles/nature16961">AlphaGo</a> is using
multi-task learning. Thus, multi-task learning has proven value in many practical
settings.</p>
<p>Multi-task learning works only if tasks are related, of course, and not all
tasks are. If unrelated tasks are included, they may degrade the performance of
multi-task models. Tasks are likely related if they are drawn from the same
domain. The startup
<a href="https://blog.cardiogr.am/screening-for-hypertension-and-sleep-apnea-with-deepheart-416c9bc03efc">Cardiogr.am</a>
trained a multi-task model to predict hypertension and sleep apnea from data
recorded by wearable heart rate sensors, and found beneficial effects.  These
beneficial effects may be rooted in shared biology; the autonomic nervous
system links your heart with your brain, stomach, esophagus, liver, intestines,
pancreas, and, importantly, your blood vessels. The algorithm likely learned
heart rate variability as a predictive feature for both tasks; two independent
studies showed associations between <a href="https://www.ncbi.nlm.nih.gov/m/pubmed/14581296/#fft">heart rate variability and
hypertension</a> and <a href="https://link.springer.com/article/10.1007%2FBF02345072">heart
rate variabiliy and sleep
apnea</a>. Their results
highlight one of the fundamental benefits of multi-task learning: multi-task
models learn, in unsupervised fashion, the relation between tasks and extract
features that can support not just one but all tasks. Models trained to learn
these more abstract features tend to generalize better to new data and
(related) tasks. In &ldquo;machine-learning speak,&rdquo; multi-task learning prevents
overfitting and helps with model transfer.</p>
<p>Multi-task learning also offers a potential savings in processing time, power,
and training data. Multi-task learning is a way of training a model to do more
than one thing at a time; it can also be used to do the same thing for more
than one set of data. Using multi-task learning in such a way allows for <em>data
augmentation</em>: learning from several smaller datasets what one would otherwise
need a single large dataset to do. While a single-task model might be able to
find meaningful patterns in a large clinical data set (as long as the clinical
data was collected under a single protocol), a multi-task model can find
meaningful patterns across data collected under multiple protocols.</p>
<p>Given the value of a multi-task approach, we are likely to see more applications of multi-task learning across a range of industries and uses cases.  Already, we have seen the following:</p>
<ul>
<li><a href="https://arxiv.org/abs/1708.09843">Medical Imagery</a> - Disease detection from medical imagery can be made more accurate with less data.</li>
<li><a href="https://arxiv.org/abs/1709.05932">Aerial Imagery</a> - More accurate structure footprints can be learned using multi-task learning, facilitating property value estimates.</li>
<li><a href="http://www.mdpi.com/2072-4292/9/11/1099">Agriculture</a> - In-field spectroscopy detects multiple chemical profiles at once, and has made precision farming more efficient.</li>
<li><a href="https://arxiv.org/abs/1703.00564">Drug Discovery</a> - The ability of compounds to bind to several different kinds of receptor sites can be predicted concurrently.</li>
<li><a href="">Genomics</a> - Using multi-task learning for data augmentation allows for learning across multiple cohorts of research subjects, which can ensure that any findings generalize better to a broader population.</li>
<li><a href="https://arxiv.org/abs/1703.07771">Healthcare</a> - models trained by multi-task learning outperformed several (though <em>not all</em>) single-task learning models at predicting hospital stay length, mortality rate, disease phenotype (specific medical problem), and decompensation (organ failure).</li>
<li><a href="https://bons.ai/">Robotics</a> - multi-task learning enables learning complex operations as multiple, related, tasks that eventually culminate in a final goal for a robotic device.</li>
<li><a href="http://www.aclweb.org/anthology/E17-1015">Natural Language Processing</a> - multi-task learning has improved the detection of mental health issues based on social media data.</li>
</ul>
<p>We invite anyone interested in supercharging their classification algorithms
using multi-task learning to our upcoming
<a href="https://www.cloudera.com/content/dam/www/marketing/resources/webinars/Multi-task-learning-recorded-webinar.png.landing.html">webinar</a>.</p>

    <div class="spacer"></div>
    <div>
      <div style="width: 100%; height: 2px; background: #ccc; margin-top: -1px; margin-bottom: -1px;"></div>
    </div>
    <div class="spacer"></div>
  </div>
</div>


<div class="container">
  <div class="spacer"></div>
  <h2 class="clear">Read more</h2>
  <div class="spacer"></div>
  <div style="display: grid; grid-template-columns: 1fr 1fr; grid-column-gap: 2ch;">
    <div>
      
      <div class="small">Newer</div>
      <div>
  <h5 style="margin-bottom: 0px;">
    <span>Jun 29, 2018</span> &middot;
    <span style="text-transform: capitalize;">
      newsletter
    </span>
  </h5>
  
    <div><a href="/2018/06/29/deep-learning-vendor-update-hyperparameter-tuning-systems.html"><strong>Deep Learning Vendor Update: Hyperparameter Tuning Systems</strong></a></div>
  
  <div class="spacer"></div>
</div>


      
    </div>
    <div>
      
      <div class="small">Older</div>
      <div>
  <h5 style="margin-bottom: 0px;">
    <span>May 31, 2018</span> &middot;
    <span style="text-transform: capitalize;">
      newsletter
    </span>
  </h5>
  
    <div><a href="/2018/05/31/rules-to-learn-by.html"><strong>Rules to Learn By</strong></a></div>
  
  <div class="spacer"></div>
</div>


      
    </div>
  </div>
</div>

<div class="container">
<div class="spacer"></div>
<div>
  <div style="width: 100%; height: 2px; background: #ccc; margin-top: -1px; margin-bottom: -1px;"></div>
</div>
<div class="spacer"></div>
<div class="spacer"></div>
</div>

<div class="container">
  

<h2 class="clear">Latest posts</h2>
<div class="spacer"></div>

<div id="posts-holder"> 
  
    <div class="post-link" style="position: relative">
  <h5 style="margin-bottom: 4px;">
    <span>May 27, 2021</span> &middot;
    <span style="text-transform: capitalize;">
      post
    </span>
  </h5>
  
  <a href="/2021/05/27/pre-trained-models-as-a-strong-baseline-for-automatic-signature-verification.html" class="preview-image-holder">
    <img class="preview-image" src="/images/hugo/ff20_blog2_workflow-1622116594.png" />
  </a>
  
  <div>
    
    <a href="/2021/05/27/pre-trained-models-as-a-strong-baseline-for-automatic-signature-verification.html"
       ><h2 style="margin-bottom: 4px;">Pre-trained Models as a Strong Baseline for Automatic Signature Verification</h2></a
     >
     
  </div>
  <div class="small" style="height: 4.5em; overflow: hidden;">
    By Victor and Andrew.
Figure 1. Baseline approach for automatic signature verification using pre-trained models As discussed in our introductory blog post, offline signature verification is a biometric verification task that aims to discriminate between genuine and forged samples of handwritten signatures. This is a particularly important form of verification due to the ubiquitous use of handwritten signatures as a means of personal identification in legal contracts, administrative forms, and financial documents.
  </div>
  <div
    style="width:100%;white-space: nowrap; overflow: hidden; text-overflow: ellipsis;"
    >
    
      <a href="/2021/05/27/pre-trained-models-as-a-strong-baseline-for-automatic-signature-verification.html">...read more</a>
    
  </div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="post-link" style="position: relative">
  <h5 style="margin-bottom: 4px;">
    <span>May 26, 2021</span> &middot;
    <span style="text-transform: capitalize;">
      post
    </span>
  </h5>
  
  <a href="/2021/05/26/deep-learning-for-automatic-offline-signature-verification.html" class="preview-image-holder">
    <img class="preview-image" src="/images/hugo/metricblog/signature_pipeline.png" />
  </a>
  
  <div>
    
    <a href="/2021/05/26/deep-learning-for-automatic-offline-signature-verification.html"
       ><h2 style="margin-bottom: 4px;">Deep Learning for Automatic Offline Signature Verification</h2></a
     >
     
  </div>
  <div class="small" style="height: 4.5em; overflow: hidden;">
    By Victor and Andrew.
Figure 1. A summary of tasks that comprise the automatic signature verification pipeline TLDR; We are working on a project - applying deep learning models to verify signatures - and will be writing about this process. This post is the first in the series and provides an overview of the signature verification task, use cases and challenges.  Given two signatures, automatic signature verification (ASV) seeks to determine if they are produced by the same user (genuine signatures) or different users (potential forgeries).
  </div>
  <div
    style="width:100%;white-space: nowrap; overflow: hidden; text-overflow: ellipsis;"
    >
    
      <a href="/2021/05/26/deep-learning-for-automatic-offline-signature-verification.html">...read more</a>
    
  </div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="post-link" style="position: relative">
  <h5 style="margin-bottom: 4px;">
    <span>Nov 15, 2020</span> &middot;
    <span style="text-transform: capitalize;">
      post
    </span>
  </h5>
  
  <a href="/2020/11/15/representation-learning-101-for-software-engineers.html" class="preview-image-holder">
    <img class="preview-image" src="/images/hugo/representationlearning.png" />
  </a>
  
  <div>
    
    <a href="/2020/11/15/representation-learning-101-for-software-engineers.html"
       ><h2 style="margin-bottom: 4px;">Representation Learning 101 for Software Engineers</h2></a
     >
     
  </div>
  <div class="small" style="height: 4.5em; overflow: hidden;">
    
    <span>
      by 
      <span
        ><a href="https://twitter.com/vykthur">Victor Dibia</a>
        &middot; </span
      >
    </span>
    Figure 1: Overview of representation learning methods. TLDR; Good representations of data (e.g., text, images) are critical for solving many tasks (e.g., search or recommendations). Deep representation learning yields state of the art results when used to create these representations. In this article, we review methods for representation learning and walk through an example using pretrained models.  Introduction Deep Neural Networks (DNNs) have become a particularly useful tool in building intelligent systems that simplify cognitive tasks for users.
  </div>
  <div
    style="width:100%;white-space: nowrap; overflow: hidden; text-overflow: ellipsis;"
    >
    
      <a href="/2020/11/15/representation-learning-101-for-software-engineers.html">...read more</a>
    
  </div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="post-link" style="position: relative">
  <h5 style="margin-bottom: 4px;">
    <span>Jun 22, 2020</span> &middot;
    <span style="text-transform: capitalize;">
      post
    </span>
  </h5>
  
  <a href="/2020/06/22/how-to-explain-huggingface-bert-for-question-answering-nlp-models-with-tf-2.0.html" class="preview-image-holder">
    <img class="preview-image" src="/images/hugo/explanation-1592852095.jpg" />
  </a>
  
  <div>
    
    <a href="/2020/06/22/how-to-explain-huggingface-bert-for-question-answering-nlp-models-with-tf-2.0.html"
       ><h2 style="margin-bottom: 4px;">How to Explain HuggingFace BERT for Question Answering NLP Models with TF 2.0</h2></a
     >
     
  </div>
  <div class="small" style="height: 4.5em; overflow: hidden;">
    
    <span>
      by 
      <span
        ><a href="https://twitter.com/vykthur">Victor</a>
        &middot; </span
      >
    </span>
    Given a question and a passage, the task of Question Answering (QA) focuses on identifying the exact span within the passage that answers the question.
Figure 1: In this sample, a BERTbase model gets the answer correct (Achaemenid Persia). Model gradients show that the token &ldquo;subordinate ..&rdquo; is impactful in the selection of an answer to the question &ldquo;Macedonia was under the rule of which country?&quot;. This makes sense .. good for BERTbase.
  </div>
  <div
    style="width:100%;white-space: nowrap; overflow: hidden; text-overflow: ellipsis;"
    >
    
      <a href="/2020/06/22/how-to-explain-huggingface-bert-for-question-answering-nlp-models-with-tf-2.0.html">...read more</a>
    
  </div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="post-link" style="position: relative">
  <h5 style="margin-bottom: 4px;">
    <span>Jun 16, 2020</span> &middot;
    <span style="text-transform: capitalize;">
      notebook
    </span>
  </h5>
  
  <a href="/2020/06/16/evaluating-qa-metrics-predictions-and-the-null-response.html" class="preview-image-holder">
    <img class="preview-image" src="/images/hugo/shotwin-2020-06-16_09-31-48-1592314597.png" />
  </a>
  
  <div>
    
    <a href="https://qa.fastforwardlabs.com/no%20answer/null%20threshold/bert/distilbert/exact%20match/f1/robust%20predictions/2020/06/09/Evaluating_BERT_on_SQuAD.html" target="_blank">
      <h2 style="margin-bottom: 4px;">Evaluating QA: Metrics, Predictions, and the Null Response →</h2></a
    >
    
  </div>
  <div class="small" style="height: 4.5em; overflow: hidden;">
    
    <span>
      by 
      <span
        ><a href="https://www.linkedin.com/in/melanierbeck">Melanie</a>
        &middot; </span
      >
    </span>
    A deep dive into computing QA predictions and when to tell BERT to zip it! In our last post, Building a QA System with BERT on Wikipedia, we used the HuggingFace framework to train BERT on the SQuAD2.0 dataset and built a simple QA system on top of the Wikipedia search engine. This time, we&rsquo;ll look at how to assess the quality of a BERT-like model for Question Answering.
  </div>
  <div
    style="width:100%;white-space: nowrap; overflow: hidden; text-overflow: ellipsis;"
    >
    
      <a href="https://qa.fastforwardlabs.com/no%20answer/null%20threshold/bert/distilbert/exact%20match/f1/robust%20predictions/2020/06/09/Evaluating_BERT_on_SQuAD.html" target="_blank">
        	
        qa.fastforwardlabs.com
      </a>
    
  </div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="post-link" style="position: relative">
  <h5 style="margin-bottom: 4px;">
    <span>May 19, 2020</span> &middot;
    <span style="text-transform: capitalize;">
      notebook
    </span>
  </h5>
  
  <a href="/2020/05/19/building-a-qa-system-with-bert-on-wikipedia.html" class="preview-image-holder">
    <img class="preview-image" src="/images/hugo/markus-spiske-C0koz3G1I4I-unsplash.jpg" />
  </a>
  
  <div>
    
    <a href="https://qa.fastforwardlabs.com/pytorch/hugging%20face/wikipedia/bert/transformers/2020/05/19/Getting_Started_with_QA.html" target="_blank">
      <h2 style="margin-bottom: 4px;">Building a QA System with BERT on Wikipedia →</h2></a
    >
    
  </div>
  <div class="small" style="height: 4.5em; overflow: hidden;">
    
    <span>
      by 
      <span
        ><a href="https://www.linkedin.com/in/melanierbeck">Melanie</a>
        &middot; </span
      >
    </span>
    So you&rsquo;ve decided to build a QA system. You want to start with something simple and general so you plan to make it open domain using Wikipedia as a corpus for answering questions. You want to use the best NLP that your compute resources allow (you&rsquo;re lucky enough to have access to a GPU) so you&rsquo;re going to focus on the big, flashy Transformer models that are all the rage these days.
  </div>
  <div
    style="width:100%;white-space: nowrap; overflow: hidden; text-overflow: ellipsis;"
    >
    
      <a href="https://qa.fastforwardlabs.com/pytorch/hugging%20face/wikipedia/bert/transformers/2020/05/19/Getting_Started_with_QA.html" target="_blank">
        	
        qa.fastforwardlabs.com
      </a>
    
  </div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
</div>

<div>
  <button id="load_more" style="width: 100%;">load more</button>
</div>
<div class="spacer"></div>
<div class="spacer"></div>

<script>
  window.addEventListener('load', () => {
    let $posts_holder = document.getElementById('posts-holder')
    let $load_more = document.getElementById('load_more')
    let next_page = 2
    $load_more.addEventListener('click', () => {
      fetch(`/posts/page/${next_page}.html`).then(r =>r.text()).then(r => {
        let el = document.createElement('html')
        el.innerHTML = r
        next_page += 1
        let $posts = el.querySelector('#posts-holder').children
        for (let i=0; i< $posts.length; i++) {
          let $post = $posts[i].cloneNode(true)
          $posts_holder.appendChild($post)
        }
      })
    })
  })
</script>


  <h3 class="clear">Popular posts</h3>
<div class="spacer"></div>
<div>
  
    <div>
  <h5 style="margin-bottom: 0px;">
    <span>Oct 30, 2019</span> &middot;
    <span style="text-transform: capitalize;">
      newsletter
    </span>
  </h5>
  
    <div><a href="/2019/10/30/exciting-applications-of-graph-neural-networks.html"><strong>Exciting Applications of Graph Neural Networks</strong></a></div>
  
  <div class="spacer"></div>
</div>


  
    <div>
  <h5 style="margin-bottom: 0px;">
    <span>Nov 14, 2018</span> &middot;
    <span style="text-transform: capitalize;">
      post
    </span>
  </h5>
  
    <div><a href="/2018/11/14/federated-learning-distributed-machine-learning-with-data-locality-and-privacy.html"><strong>Federated learning: distributed machine learning with data locality and privacy</strong></a></div>
  
  <div class="spacer"></div>
</div>


  
    <div>
  <h5 style="margin-bottom: 0px;">
    <span>Apr 10, 2018</span> &middot;
    <span style="text-transform: capitalize;">
      post
    </span>
  </h5>
  
    <div><a href="/2018/04/10/pytorch-for-recommenders-101.html"><strong>PyTorch for Recommenders 101</strong></a></div>
  
  <div class="spacer"></div>
</div>


  
    <div>
  <h5 style="margin-bottom: 0px;">
    <span>Oct 4, 2017</span> &middot;
    <span style="text-transform: capitalize;">
      post
    </span>
  </h5>
  
    <div><a href="/2017/10/04/first-look-using-three.js-for-2d-data-visualization.html"><strong>First Look: Using Three.js for 2D Data Visualization</strong></a></div>
  
  <div class="spacer"></div>
</div>


  
    <div>
  <h5 style="margin-bottom: 0px;">
    <span>Aug 22, 2016</span> &middot;
    <span style="text-transform: capitalize;">
      whitepaper
    </span>
  </h5>
  
    <div><a href="/2016/08/22/under-the-hood-of-the-variational-autoencoder-in-prose-and-code.html"><strong>Under the Hood of the Variational Autoencoder (in Prose and Code)</strong></a></div>
  
  <div class="spacer"></div>
</div>


  
    <div>
  <h5 style="margin-bottom: 0px;">
    <span>Feb 24, 2016</span> &middot;
    <span style="text-transform: capitalize;">
      post
    </span>
  </h5>
  
    <div><a href="/2016/02/24/hello-world-in-keras-or-scikit-learn-versus-keras.html"><strong>&#34;Hello world&#34; in Keras (or, Scikit-learn versus Keras)</strong></a></div>
  
  <div class="spacer"></div>
</div>


  
</div>

</div>

<div class="spacer"></div>
<div style="background: #efefef;">
  <div class="spacer"></div>
  <div class="spacer"></div>
  <div class="container">
  <h1 class="clear">Reports</h1>
  <div style="color: #444;">In-depth guides to specific machine learning capabilities</div>
</div>
<div class="spacer"></div>
<div style="max-width: 96ch; margin: 0 auto; padding-left: 1ch; padding-right: 1ch;">
  
    <div class="report-link" style="position: relative;">
  <h5 style="margin-bottom: 0">FF19</h5>
  <h2 style="padding-top: 0; margin-bottom: 4px;"><a href="https://session-based-recommenders.fastforwardlabs.com/" target="_blank">Session-based Recommender Systems</a></h2>
  <a class="report-image" href="https://session-based-recommenders.fastforwardlabs.com/" target="_blank" style="display: block;">
    <img style="max-width: 31ch; display: block;" src="/images/reports/ff19-cover.png" />
  </a>
  <div class="small">Being able to recommend an item of interest to a user (based on their past preferences) is a highly relevant problem in practice. A key trend over the past few years has been session-based recommendation algorithms that provide recommendations solely based on a user’s interactions in an ongoing session, and which do not require the existence of user profiles or their entire historical preferences. This report explores a simple, yet powerful, NLP-based approach (word2vec) to recommend a next item to a user. While NLP-based approaches are generally employed for linguistic tasks, here we exploit them to learn the structure induced by a user’s behavior or an item’s nature.</div>
  <div><a href="https://session-based-recommenders.fastforwardlabs.com/" target="_blank">Read the report&nbsp; →</a></div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="report-link" style="position: relative;">
  <h5 style="margin-bottom: 0">FF18</h5>
  <h2 style="padding-top: 0; margin-bottom: 4px;"><a href="https://few-shot-text-classification.fastforwardlabs.com/" target="_blank">Few-Shot Text Classification</a></h2>
  <a class="report-image" href="https://few-shot-text-classification.fastforwardlabs.com/" target="_blank" style="display: block;">
    <img style="max-width: 31ch; display: block;" src="/images/reports/ff18-combo.png" />
  </a>
  <div class="small">Text classification can be used for sentiment analysis, topic assignment, document identification, article recommendation, and more. While dozens of techniques now exist for this fundamental task, many of them require massive amounts of labeled data in order to be useful. Collecting annotations for your use case is typically one of the most costly parts of any machine learning application. In this report, we explore how latent text embeddings can be used with few (or even zero) training examples and provide insights into best practices for implementing this method.</div>
  <div><a href="https://few-shot-text-classification.fastforwardlabs.com/" target="_blank">Read the report&nbsp; →</a></div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="report-link" style="position: relative;">
  <h5 style="margin-bottom: 0">FF16</h5>
  <h2 style="padding-top: 0; margin-bottom: 4px;"><a href="https://structural-time-series.fastforwardlabs.com" target="_blank">Structural Time Series</a></h2>
  <a class="report-image" href="https://structural-time-series.fastforwardlabs.com" target="_blank" style="display: block;">
    <img style="max-width: 31ch; display: block;" src="/images/reports/ff16-combo.png" />
  </a>
  <div class="small">Time series data is ubiquitous. This report examines generalized additive models, which give us a simple, flexible, and interpretable means for modeling time series by decomposing them into structural components. We look at the benefits and trade-offs of taking a curve-fitting approach to time series, and demonstrate its use via Facebook’s Prophet library on a demand forecasting problem.</div>
  <div><a href="https://structural-time-series.fastforwardlabs.com" target="_blank">Read the report&nbsp; →</a></div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="report-link" style="position: relative;">
  <h5 style="margin-bottom: 0">FF15</h5>
  <h2 style="padding-top: 0; margin-bottom: 4px;"><a href="https://meta-learning.fastforwardlabs.com" target="_blank">Meta-Learning</a></h2>
  <a class="report-image" href="https://meta-learning.fastforwardlabs.com" target="_blank" style="display: block;">
    <img style="max-width: 31ch; display: block;" src="/images/reports/ff15-combo.png" />
  </a>
  <div class="small">In contrast to how humans learn, deep learning algorithms need vast amounts of data and compute and may yet struggle to generalize. Humans are successful in adapting quickly because they leverage their knowledge acquired from prior experience when faced with new problems. In this report, we explain how meta-learning can leverage previous knowledge acquired from data to solve novel tasks quickly and more efficiently during test time</div>
  <div><a href="https://meta-learning.fastforwardlabs.com" target="_blank">Read the report&nbsp; →</a></div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="report-link" style="position: relative;">
  <h5 style="margin-bottom: 0">FF14</h5>
  <h2 style="padding-top: 0; margin-bottom: 4px;"><a href="https://qa.fastforwardlabs.com" target="_blank">Automated Question Answering</a></h2>
  <a class="report-image" href="https://qa.fastforwardlabs.com" target="_blank" style="display: block;">
    <img style="max-width: 31ch; display: block;" src="/images/reports/ff14-combo.png" />
  </a>
  <div class="small">Automated question answering is a user-friendly way to extract information from data using natural language. Thanks to recent advances in natural language processing, question answering capabilities from unstructured text data have grown rapidly. This blog series offers a walk-through detailing the technical and practical aspects of building an end-to-end question answering system.</div>
  <div><a href="https://qa.fastforwardlabs.com" target="_blank">Read the report&nbsp; →</a></div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="report-link" style="position: relative;">
  <h5 style="margin-bottom: 0">FF13</h5>
  <h2 style="padding-top: 0; margin-bottom: 4px;"><a href="https://ff13.fastforwardlabs.com" target="_blank">Causality for Maching Learning</a></h2>
  <a class="report-image" href="https://ff13.fastforwardlabs.com" target="_blank" style="display: block;">
    <img style="max-width: 31ch; display: block;" src="/images/reports/ff13-combo.png" />
  </a>
  <div class="small">The intersection of causal inference and machine learning is a rapidly expanding area of research that&#39;s already yielding capabilities to enable building more robust, reliable, and fair machine learning systems. This report offers an introduction to causal reasoning including causal graphs and invariant prediction and how to apply causal inference tools together with classic machine learning techniques in multiple use-cases.</div>
  <div><a href="https://ff13.fastforwardlabs.com" target="_blank">Read the report&nbsp; →</a></div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="report-link" style="position: relative;">
  <h5 style="margin-bottom: 0">FF06-2020</h5>
  <h2 style="padding-top: 0; margin-bottom: 4px;"><a href="https://ff06-2020.fastforwardlabs.com" target="_blank">Interpretability</a></h2>
  <a class="report-image" href="https://ff06-2020.fastforwardlabs.com" target="_blank" style="display: block;">
    <img style="max-width: 31ch; display: block;" src="/images/reports/ff06-2020-combo.png" />
  </a>
  <div class="small">Interpretability, or the ability to explain why and how a system makes a decision, can help us improve models, satisfy regulations, and build better products. Black-box techniques like deep learning have delivered breakthrough capabilities at the cost of interpretability. In this report, recently updated to include techniques like SHAP, we show how to make models interpretable without sacrificing their capabilities or accuracy.</div>
  <div><a href="https://ff06-2020.fastforwardlabs.com" target="_blank">Read the report&nbsp; →</a></div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="report-link" style="position: relative;">
  <h5 style="margin-bottom: 0">FF12</h5>
  <h2 style="padding-top: 0; margin-bottom: 4px;"><a href="https://ff12.fastforwardlabs.com" target="_blank">Deep Learning for Anomaly Detection</a></h2>
  <a class="report-image" href="https://ff12.fastforwardlabs.com" target="_blank" style="display: block;">
    <img style="max-width: 31ch; display: block;" src="/images/reports/ff12-combo.png" />
  </a>
  <div class="small">From fraud detection to flagging abnormalities in imaging data, there are countless applications for automatic identification of abnormal data. This process can be challenging, especially when working with large, complex data. This report explores deep learning approaches (sequence models, VAEs, GANs) for anomaly detection, when to use them, performance benchmarks, and product possibilities.</div>
  <div><a href="https://ff12.fastforwardlabs.com" target="_blank">Read the report&nbsp; →</a></div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="report-link" style="position: relative;">
  <h5 style="margin-bottom: 0">FF09</h5>
  <h2 style="padding-top: 0; margin-bottom: 4px;"><a href="https://federated.fastforwardlabs.com/" target="_blank">Federated Learning</a></h2>
  <a class="report-image" href="https://federated.fastforwardlabs.com/" target="_blank" style="display: block;">
    <img style="max-width: 31ch; display: block;" src="/images/reports/ff09-combo.png" />
  </a>
  <div class="small">Federated Learning makes it possible to build machine learning systems without direct access to training data. The data remains in its original location, which helps to ensure privacy and reduces communication costs. Federated learning is a great fit for smartphones and edge hardware, healthcare and other privacy-sensitive use cases, and industrial applications such as predictive maintenance.</div>
  <div><a href="https://federated.fastforwardlabs.com/" target="_blank">Read the report&nbsp; →</a></div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="report-link" style="position: relative;">
  <h5 style="margin-bottom: 0">FF03-2019</h5>
  <h2 style="padding-top: 0; margin-bottom: 4px;"><a href="https://deep-learning-image-analysis.fastforwardlabs.com/" target="_blank">Deep Learning for Image Analysis: 2019 Edition</a></h2>
  <a class="report-image" href="https://deep-learning-image-analysis.fastforwardlabs.com/" target="_blank" style="display: block;">
    <img style="max-width: 31ch; display: block;" src="/images/reports/ff03-2019-combo.png" />
  </a>
  <div class="small">Convolutional Neural Networks (CNN) excel at learning meaningful representations of features and concepts within images. These capabilities make CNNs extremely valuable for solving problems in domains such as medical imaging, autonomous driving, manufacturing, robotics, and urban planning. In this report, we show how to select the right deep learning models for image analysis tasks and techniques for debugging deep learning models.</div>
  <div><a href="https://deep-learning-image-analysis.fastforwardlabs.com/" target="_blank">Read the report&nbsp; →</a></div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="report-link" style="position: relative;">
  <h5 style="margin-bottom: 0">FF03</h5>
  <h2 style="padding-top: 0; margin-bottom: 4px;"><a href="https://deep-learning-image-classic.fastforwardlabs.com/" target="_blank">Deep Learning: Image Analysis</a></h2>
  <a class="report-image" href="https://deep-learning-image-classic.fastforwardlabs.com/" target="_blank" style="display: block;">
    <img style="max-width: 31ch; display: block;" src="/images/reports/ff03-classic-combo.png" />
  </a>
  <div class="small">Deep learning, or highly-connected neural networks, offers fascinating new capabilities for image analysis. Using deep learning, computers can now learn to identify objects in images. This report explores the history and current state of the field, predicts future developments, and explains how to apply deep learning today.</div>
  <div><a href="https://deep-learning-image-classic.fastforwardlabs.com/" target="_blank">Read the report&nbsp; →</a></div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
</div>


</div>

<div class="spacer"></div>
<div class="spacer"></div>
 
<div class="container">
  <h1 class="clear">Prototypes</h1>
  <div style="color: #444;">Machine learning prototypes and interactive notebooks</div>
  <div class="spacer"></div>
</div>
<div id="prototypes-holder">
  
  <div style="display: flex; flex-direction: column; position: relative; padding-left: 1ch; padding-right: 1ch; height: 360px;">
  <div>
    <h5 style="margin-bottom: 0">Library</h5>
    <h2 style="padding-top: 0; margin-bottom: 0;"><a href="https://neuralqa.fastforwardlabs.com" target="_blank">NeuralQA</a></h2>
  </div>
  <div style="flex: 1 1 auto; position: relative;">
    <a href="https://neuralqa.fastforwardlabs.com" target="_blank" style="display: block; position: absolute; top: 0.375rem; width: 100%; height: calc(100% - 0.875rem); background-image: url('/images/hugo/neuralqa-1596123511.jpg'); background-size: contain; background-position: center left; background-repeat: no-repeat;"></a>
  </div>
  <div>
    <div class="small">A usable library for question answering on large datasets.</div>
    <div style="width: 100%; white-space: nowrap; overflow: hidden; text-overflow: ellipsis;"><a href="https://neuralqa.fastforwardlabs.com" target="_blank">https://neuralqa.fastforwardlabs.com</a></div>
  </div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
  <div style="display: flex; flex-direction: column; position: relative; padding-left: 1ch; padding-right: 1ch; height: 360px;">
  <div>
    <h5 style="margin-bottom: 0">Notebook</h5>
    <h2 style="padding-top: 0; margin-bottom: 0;"><a href="https://colab.research.google.com/drive/1tTiOgJ7xvy3sjfiFC9OozbjAX1ho8WN9?usp=sharing" target="_blank">Explain BERT for Question Answering Models</a></h2>
  </div>
  <div style="flex: 1 1 auto; position: relative;">
    <a href="https://colab.research.google.com/drive/1tTiOgJ7xvy3sjfiFC9OozbjAX1ho8WN9?usp=sharing" target="_blank" style="display: block; position: absolute; top: 0.375rem; width: 100%; height: calc(100% - 0.875rem); background-image: url('/images/hugo/distilexplanation-1592852137.jpg'); background-size: contain; background-position: center left; background-repeat: no-repeat;"></a>
  </div>
  <div>
    <div class="small">Tensorflow 2.0 notebook to explain and visualize a HuggingFace BERT for Question Answering model.</div>
    <div style="width: 100%; white-space: nowrap; overflow: hidden; text-overflow: ellipsis;"><a href="https://colab.research.google.com/drive/1tTiOgJ7xvy3sjfiFC9OozbjAX1ho8WN9?usp=sharing" target="_blank">https://colab.research.google.com/drive/1tTiOgJ7xvy3sjfiFC9OozbjAX1ho8WN9?usp=sharing</a></div>
  </div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
  <div style="display: flex; flex-direction: column; position: relative; padding-left: 1ch; padding-right: 1ch; height: 360px;">
  <div>
    <h5 style="margin-bottom: 0">Notebooks</h5>
    <h2 style="padding-top: 0; margin-bottom: 0;"><a href="https://qa.fastforwardlabs.com" target="_blank">NLP for Question Answering</a></h2>
  </div>
  <div style="flex: 1 1 auto; position: relative;">
    <a href="https://qa.fastforwardlabs.com" target="_blank" style="display: block; position: absolute; top: 0.375rem; width: 100%; height: calc(100% - 0.875rem); background-image: url('/images/uploads/qa.png'); background-size: contain; background-position: center left; background-repeat: no-repeat;"></a>
  </div>
  <div>
    <div class="small">Ongoing posts and code documenting the process of building a question answering model.</div>
    <div style="width: 100%; white-space: nowrap; overflow: hidden; text-overflow: ellipsis;"><a href="https://qa.fastforwardlabs.com" target="_blank">https://qa.fastforwardlabs.com</a></div>
  </div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
  <div style="display: flex; flex-direction: column; position: relative; padding-left: 1ch; padding-right: 1ch; height: 360px;">
  <div>
    <h5 style="margin-bottom: 0">Notebook</h5>
    <h2 style="padding-top: 0; margin-bottom: 0;"><a href="https://colab.research.google.com/drive/1pjPzsw_uZew-Zcz646JTkRDhF2GkPk0N" target="_blank">Interpretability Revisited: SHAP and LIME</a></h2>
  </div>
  <div style="flex: 1 1 auto; position: relative;">
    <a href="https://colab.research.google.com/drive/1pjPzsw_uZew-Zcz646JTkRDhF2GkPk0N" target="_blank" style="display: block; position: absolute; top: 0.375rem; width: 100%; height: calc(100% - 0.875rem); background-image: url('/images/uploads/shap-and-lime.png'); background-size: contain; background-position: center left; background-repeat: no-repeat;"></a>
  </div>
  <div>
    <div class="small">Explore how to use LIME and SHAP for interpretability.</div>
    <div style="width: 100%; white-space: nowrap; overflow: hidden; text-overflow: ellipsis;"><a href="https://colab.research.google.com/drive/1pjPzsw_uZew-Zcz646JTkRDhF2GkPk0N" target="_blank">https://colab.research.google.com/drive/1pjPzsw_uZew-Zcz646JTkRDhF2GkPk0N</a></div>
  </div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
</div>
<div class="container">
  <div ><button id="load_all_prototypes" style="width: 100%;">load all</button></div>
</div>

<script>
  
  window.addEventListener('load', () => {
    let $prototypes_holder = document.getElementById('prototypes-holder')
    let $load_more = document.getElementById('load_all_prototypes')
    $load_more.addEventListener('click', () => {
      fetch(`/prototypes.html`).then(r =>r.text()).then(r => {
        $load_more.remove()
        let el = document.createElement('html')
        el.innerHTML = r
        let $posts = el.querySelector('#prototypes-holder')
        $prototypes_holder.innerHTML = $posts.innerHTML
      })
    })
  })
</script>



<div class="spacer"></div>
<div class="spacer"></div>

<div class="container">
  <div>
    <h1 class="clear">About</h1>
    <div>
      Cloudera Fast Forward is an applied machine learning reseach group.<br />
      <a
        href="https://www.cloudera.com/products/fast-forward-labs-research.html"
        >Cloudera</a
      >&nbsp;&nbsp;
      <a
        href="https://blog.fastforwardlabs.com"
        >Blog</a
      >&nbsp;&nbsp;
      <a href="https://twitter.com/fastforwardlabs">Twitter</a>
    </div>
  </div>
</div>



<div class="spacer"></div>
<div class="spacer"></div>


      </main>
 </body>
</html>
