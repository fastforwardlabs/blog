<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />
    
<title>Federated learning: distributed machine learning with data locality and privacy</title>
<meta property="og:title" content="Federated learning: distributed machine learning with data locality and privacy">
<meta property="description" content="We’re excited to release Federated Learning, the latest report and prototype from Cloudera Fast Forward Labs.
Federated learning makes it possible to build machine learning systems without direct access to training data. The data remains in its original location, which helps to ensure privacy and reduces communication costs.
This article is about the technical side of federated learning.
If you’d like to learn more:
 Read about the business and product side of federated learning on the Cloudera VISION blog Explore our interactive federated learning prototype, Turbofan Tycoon Register for our webinar (Thursday, November 15, 2018) Get access to the full 85 page report and advising time with the Fast Forward Labs team by becoming a Cloudera Fast Forward Labs client  The federated learning setting Two things define the federated learning setting.">
<meta property="og:description" content="We’re excited to release Federated Learning, the latest report and prototype from Cloudera Fast Forward Labs.
Federated learning makes it possible to build machine learning systems without direct access to training data. The data remains in its original location, which helps to ensure privacy and reduces communication costs.
This article is about the technical side of federated learning.
If you’d like to learn more:
 Read about the business and product side of federated learning on the Cloudera VISION blog Explore our interactive federated learning prototype, Turbofan Tycoon Register for our webinar (Thursday, November 15, 2018) Get access to the full 85 page report and advising time with the Fast Forward Labs team by becoming a Cloudera Fast Forward Labs client  The federated learning setting Two things define the federated learning setting.">
<meta property="og:image" content="https://blog.fastforwardlabs.com/images/editor_uploads/2018-11-14-214557-ff09_07.png">
<meta property="og:url" content="https://blog.fastforwardlabs.com/2018/11/14/federated-learning-distributed-machine-learning-with-data-locality-and-privacy.html">
<meta property="twitter:card" content="summary_large_image">
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <link rel="stylesheet" type="text/css" href="/style.css" />
    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-53030428-5', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

  </head>
  <body>
      <div class="container">
        <div class="spacer"></div>
        <div style="height: 2.5rem; padding-top: 0.35rem;">
          <a target="_blank" href="https://www.cloudera.com/products/fast-forward-labs-research.html">
            <img style="height: 2rem;" src="/images/cloudera-fast-forward-logo.png" />
          </a>
        </div>
        <div class="spacer"></div>
      </div>
      <main id="main">
        
<div class="container">
  <div>
    <h3 class="clear"><a href="/">Blog</a></h3>
  </div>
  <div class="spacer"></div>
  <div class="post">
    <h5 class="clear">
      <span>Nov 14, 2018</span> &middot;
      <span style="text-transform: capitalize;">
        post
      </span>
    </h5>
    <h1>Federated learning: distributed machine learning with data locality and privacy</h1>
    <p>We’re excited to release <em>Federated Learning</em>, the latest report and prototype from Cloudera Fast Forward Labs.</p>
<p>Federated learning makes it possible to build machine learning systems without direct access to training data. The data remains in its original location, which helps to ensure privacy and reduces communication costs.</p>
<p>This article is about the technical side of federated learning.</p>
<p>If you’d like to learn more:</p>
<ul>
<li>Read about the business and product side of federated learning on the <a href="http://vision.cloudera.com/an-introduction-to-federated-learning/">Cloudera VISION blog</a></li>
<li>Explore our interactive federated learning prototype, <a href="https://turbofan.fastforwardlabs.com/">Turbofan Tycoon</a></li>
<li><a href="https://www.cloudera.com/more/events/webinars/federated_learning.html">Register for our webinar</a> (Thursday, November 15, 2018)</li>
<li>Get access to the full 85 page report and advising time with the Fast Forward Labs team by <a href="https://www.cloudera.com/about/services-and-support/fast-forward-labs.html">becoming a Cloudera Fast Forward Labs client</a></li>
</ul>
<h2 id="the-federated-learning-setting">The federated learning setting</h2>
<p>Two things define the federated learning setting.</p>
<p>First, the training data cannot be moved away from its source. The reasons for this constraint can include privacy concerns (I don’t want share my baby photos), regulatory impediments (HIPAA, GDPR, etc.), and practical engineering blockers (the network connection is expensive, slow or unreliable, or the data is too large).</p>
<p><img src="/images/editor_uploads/2018-11-14-214557-ff09_07.png" alt=""></p>
<h5 id="federated-learning-helps-when-the-data-cannot-be-moved">Federated learning helps when the data cannot be moved.</h5>
<p>Sometimes we can work around this data locality constraint with proxy data that approximates the behavior of the real data. But almost by definition, proxy data is not as good as the real thing. For example, if you want to train a language model for smartphones, it’s better to train on language typed on smartphones than, for example, the Wikipedia corpus.</p>
<p>Second, in the federated learning setting, each source of potential training data can in principle be different from every other. In other words, the distributions of data on each source are non-IID, and the amount of data at each source can be very different.</p>
<p>In <a href="http://vision.cloudera.com/an-introduction-to-federated-learning/">our article on the Cloudera blog</a>, we describe concrete use cases that often have these characteristics: smartphones, healthcare, and predictive maintenance. In this post, we focus on the technical solution.</p>
<h2 id="federated-averaging">Federated averaging</h2>
<p>&ldquo;Federated learning&rdquo; refers to a family of algorithms that attempt to solve machine learning problems in the setting described above. They differ in important details, but share the basic idea: a server coordinates a network of nodes, each of which has training data. The nodes each train a local model, and it is that model which they share with the server.</p>
<p>Let’s be more specific by describing federated averaging, perhaps the simplest form of federated learning. This algorithm was <a href="https://arxiv.org/abs/1602.05629">published by a Google team in 2016</a>.</p>
<p><img src="/images/editor_uploads/2018-11-14-214805-ff09_09.png" alt="A diagram of federated learning. First, nodes receive the model from server and start training. Then, Nodes send their partially trained models to the server. The server takes those models and combines them to make a federated model. That federated model is sent back down to the nodes. Those models can be trained further locally as the cycle repeats."></p>
<p>The server first sends each node an instruction to train a model of a particular type, such as a linear model, a support vector machine, or, in the case of deep learning, a particular network architecture.</p>
<p>On receiving this instruction, each node trains the model on its subset of the training data. In general, training a model requires many iterations of an algorithm (such as gradient descent), but in federated learning, the nodes train their models for only a few iterations. In that sense, each node’s model is partially trained after following the server’s instruction. The nodes then send their partially trained models (but not the training data) back to the server.</p>
<p>The server combines the partially trained models to form a federated model. One way to combine the models is to take the average of each coefficient, weighting by the amount of training data available on the corresponding node.</p>
<p>The combined federated model is then transmitted back to the nodes, where it replaces their local models and is used as the starting point for another round of training. After several rounds, the federated model converges to a good global model. From round to round, the nodes can acquire new training data. Some nodes may even drop out, and others may join.</p>
<p>And crucially, the server never has direct access to the training data. By moving models rather than training data, federated learning helps to ensure privacy and minimizes communication costs.</p>
<h2 id="turbofan-tycoon">Turbofan Tycoon</h2>
<p>Every Cloudera Fast Forward Labs report comes with a prototype. This interactive prototype provides an immediate, intuitive way to understand what the technology can (and cannot!) do. And, in building it, we learn the technical details which we include in the report, and figure out best practices that help us to more effectively advise our clients.</p>
<p>The prototype for our report on Federated Learning is <a href="https://turbofan.fastforwardlabs.com/">Turbofan Tycoon</a>. In it, you play the owner of a factory that wants to do a better job of maintaining its turbofan engines. Your options are:</p>
<ul>
<li>A corrective maintenance strategy (i.e., waiting for the engines to fail)</li>
<li>A preventative maintenance strategy (i.e., maintaining each engine at a fixed time, hopefully some time before it fails)</li>
<li>A local predictive maintenance machine learning model, trained only on your failed engines</li>
<li>A federated predictive maintenance machine learning model, trained on the collective data of 80 factories (including yours), using federated learning</li>
</ul>
<p>Spoiler alert: the optimal strategy is federated learning, and the ROI relative to the alternatives huge! <a href="https://turbofan.fastforwardlabs.com/">We hope you enjoy exploring it</a>.</p>
<p><img src="/images/editor_uploads/2018-11-14-214853-ff09_browser.png" alt="A screenshot of the prototype Turbofan Tycoon."></p>
<p>To train the federated model, we wrote an implementation of federated averaging in about 100 lines of PyTorch. This implementation is a <em>simulation</em> of federated learning in the sense that no real network communication takes place. The server and the nodes all exist on one machine. However, it is an algorithmically faithful implementation: the server and nodes communicate only by sending copies of their models to each other.</p>
<p>This approach made it possible for us to experiment rapidly with very large numbers of nodes, without getting bogged down in network issues. And despite the simplification, we can reproduce many of the practical challenges that a real network would face (stragglers, dropped connections, etc.). The models trained on each node (and the federated model that is their average) are simple feed-forward neural networks with one hidden layer. We give more details in the report.</p>
<h2 id="privacy">Privacy</h2>
<p>By leaving the training data at its source, federated learning plugs the most obvious and gaping security hole in distributed machine learning. But it is important to be clear that it is not a silver bullet.</p>
<p><img src="/images/editor_uploads/2018-11-14-214957-ff09_20.png" alt=""></p>
<h5 id="it-can-be-possible-to-infer-information-about-the-data-on-a-node-from-the-models-it-sends-to-the-server">It can be possible to infer information about the data on a node from the models it sends to the server</h5>
<p>That’s because it is sometimes possible to infer things about the training data from a model. This problem is not unique to federated learning—any time you share the predictions of a trained model ,you open up this possibility. However, it is worth considering in detail in the context of federated learning for two reasons: first, preserving privacy is one of federated learning’s main goals; second, by distributing training among (potentially untrustworthy) participants, federated learning opens up new attack vectors.</p>
<p>The most indirect way to infer information about the training data requires only the ability to query the model several times. Anyone with indirect access to the model via an API can attempt to attack it in this way. This attack vector is not unique (or any more dangerous) in federated learning. (See, for example,<a href="https://arxiv.org/abs/1610.05820"> Membership Inference Attacks Against Machine Learning Models</a> and<a href="https://dl.acm.org/citation.cfm?id=2813677"> Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures</a>).</p>
<p>The usual protection against this attack is <em>differential privacy</em>. Differential privacy is a large and mathematically formal field with applications far beyond machine learning. But in a production machine learning context, the application of differential privacy generally means that the server adds noise to the model before allowing users to query it. For a modern, accessible, ML-oriented introduction to differential privacy, check out <a href="http://www.cleverhans.io/privacy/2018/04/29/privacy-and-machine-learning.html">Privacy and Machine Learning: Two Unexpected Allies</a>.</p>
<p>In a federated learning setting where the server and nodes are justified in trusting each other, this type of attack is the only concern. But if the server or nodes are not trustworthy, other kinds of attacks are possible.</p>
<p><img src="/images/editor_uploads/2018-11-14-215038-ff09_27.png" alt=""></p>
<h5 id="training-data-left-can-be-reconstructed-right-by-a-malicious-node-images-taken-from--deep-models-under-the-gan-information-leakage-from-collaborative-deep-learninghttpsarxivorgabs170207464-by-briland-hitaj-giuseppe-ateniese-and-fernando-perez-cruz">Training data (left) can be reconstructed (right) by a malicious node (images taken from <a href="https://arxiv.org/abs/1702.07464"> &ldquo;Deep Models Under the GAN: Information Leakage from Collaborative Deep Learning&rdquo;</a> by Briland Hitaj, Giuseppe Ateniese, and Fernando Perez-Cruz).</h5>
<p>For example, the server must be able to directly inspect the node’s model in order to average it. But for certain classes of model, the mere fact that a weight has changed tells you a particular feature was present in the training data. For example, suppose a model takes a bag of words as features, and the tenth word in the vocabulary is &ldquo;dumplings.&rdquo; If a node returns a model where the tenth coefficient of the model has changed, the server or an intermediary may be able to infer that the word &ldquo;dumplings&rdquo; was present in the training data on that node.</p>
<p>This attack is more difficult to carry out against modern (and more complex) models in practice. The risk can be mitigated by differential privacy (again) or secure aggregation. The differential privacy approach has each node add noise to its model before sharing it with the server (see, e.g., <a href="https://arxiv.org/abs/1805.10559">Communication-Efficient and Differentially-Private Distributed SGD</a>) <a href="https://eprint.iacr.org/2017/281">Secure aggregation protocols</a> make it possible for the server to compute the average of the node models using encrypted copies which it does not have the ability to decrypt. Both these approaches add communication and computation overhead, but that may be a trade-off worth making in highly sensitive contexts.</p>
<p><a href="https://www.cloudera.com/more/events/webinars/federated_learning.html">In our webinar</a>, we’ll be learning more about these issues from Andrew Trask of <a href="https://www.openmined.org/">OpenMined</a> and Eric Tramel of <a href="https://owkin.com/">Owkin</a>.</p>
<h2 id="personalization">Personalization</h2>
<p>In &ldquo;regular&rdquo; federated learning, the server’s goal is to use the data on every node to train a single global model, but in situations where a node plans to apply the model (not just contribute to its creation), it will usually care much more that the model captures the patterns in its data than any other node’s data. For example, if I’m a node in a network that is training a model that will help write emails that are more likely to receive replies, I care more that the model works for me than if it works for anyone else.</p>
<p>If the global model has an appropriately flexible architecture and was trained on lots of good training data, then it may be better than any local model trained on a single node because of its ability to capture many idiosyncrasies and generalize to new patterns. But it is true that, in principle and sometimes in practice, the user’s goal (local performance) can be in tension with the server’s (global performance).</p>
<p>Resolving this tension is the goal of research into personalization. In<a href="https://arxiv.org/abs/1705.10467"> Federated Multi-Task Learning</a>, Virginia Smith and collaborators frame personalization as a multi-task problem where each user’s model is a task, but there exists a structure that relates the tasks. Virginia will also be joining us for <a href="https://www.cloudera.com/more/events/webinars/federated_learning.html">our webinar</a>.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Federated learning makes it easier, safer, and cheaper to apply machine learning in the world’s most regulated, competitive, and profitable industries. It’s also an area of very active current research, with open problems in privacy, security, personalization, and other areas.</p>
<p>In this article, we’ve only scratched the surface. Our report goes into much more detail, and covers issues not mentioned here (including systems and networking issues, libraries and frameworks, and practical recommendations based on our experience building Turbofan Tycoon). We hope you <a href="https://www.cloudera.com/more/events/webinars/federated_learning.html">join the webinar</a>, <a href="https://turbofan.fastforwardlabs.com/">explore the prototype</a>, and <a href="https://www.cloudera.com/about/services-and-support/fast-forward-labs.html">get in touch</a> if you’re interested in working together.</p>
<p><em>Update:  You can watch the recorded webinar <a href="https://www.cloudera.com/more/events/webinars/federated_learning.html">here</a>.</em></p>

    <div class="spacer"></div>
    <div>
      <div style="width: 100%; height: 2px; background: #ccc; margin-top: -1px; margin-bottom: -1px;"></div>
    </div>
    <div class="spacer"></div>
  </div>
</div>


<div class="container">
  <div class="spacer"></div>
  <h2 class="clear">Read more</h2>
  <div class="spacer"></div>
  <div style="display: grid; grid-template-columns: 1fr 1fr; grid-column-gap: 2ch;">
    <div>
      
      <div class="small">Newer</div>
      <div>
  <h5 style="margin-bottom: 0px;">
    <span>Dec 6, 2018</span> &middot;
    <span style="text-transform: capitalize;">
      post
    </span>
  </h5>
  
    <div><a href="/2018/12/06/designing-turbofan-tycoon.html"><strong>Designing Turbofan Tycoon</strong></a></div>
  
  <div class="spacer"></div>
</div>


      
    </div>
    <div>
      
      <div class="small">Older</div>
      <div>
  <h5 style="margin-bottom: 0px;">
    <span>Oct 29, 2018</span> &middot;
    <span style="text-transform: capitalize;">
      newsletter
    </span>
  </h5>
  
    <div><a href="/2018/10/29/the-quest-continues-a-look-at-a-new-initiative-to-explore-human-and-machine-intelligence.html"><strong>The quest continues: a look at a new initiative to explore human and machine intelligence</strong></a></div>
  
  <div class="spacer"></div>
</div>


      
    </div>
  </div>
</div>

<div class="container">
<div class="spacer"></div>
<div>
  <div style="width: 100%; height: 2px; background: #ccc; margin-top: -1px; margin-bottom: -1px;"></div>
</div>
<div class="spacer"></div>
<div class="spacer"></div>
</div>

<div class="container">
  

<h2 class="clear">Latest posts</h2>
<div class="spacer"></div>

<div id="posts-holder"> 
  
    <div class="post-link" style="position: relative">
  <h5 style="margin-bottom: 4px;">
    <span>Jun 9, 2021</span> &middot;
    <span style="text-transform: capitalize;">
      
    </span>
  </h5>
  
  <a href="/2021/06/09/deep-metric-learning-for-signature-verification.html" class="preview-image-holder">
    <img class="preview-image" src="/images/hugo/metricblog/onlinetraining.png" />
  </a>
  
  <div>
    
    <a href="/2021/06/09/deep-metric-learning-for-signature-verification.html"
       ><h2 style="margin-bottom: 4px;">Deep Metric Learning for Signature Verification</h2></a
     >
     
  </div>
  <div class="small" style="height: 4.5em; overflow: hidden;">
    By Victor and Andrew.
TLDR; This post provides an overview of metric learning loss functions (constrastive, triplet, quadruplet and group loss), and results from applying contrastive and triplet loss to the task of signature verification. Other posts in the series are listed below: Pretrained Models as Baselines for Signature Verification  --   Part 1: Deep Learning for Automatic Offline Signature Verification: An Introduction    Part 2: Pretrained Models as Baselines for Signature Verification    Part 3: Deep Metric Learning for Signature Verification      In our previous blog post, , we discussed how pretrained models can serve as strong baselines for the task of signature verification.
  </div>
  <div
    style="width:100%;white-space: nowrap; overflow: hidden; text-overflow: ellipsis;"
    >
    
      <a href="/2021/06/09/deep-metric-learning-for-signature-verification.html">...read more</a>
    
  </div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="post-link" style="position: relative">
  <h5 style="margin-bottom: 4px;">
    <span>May 27, 2021</span> &middot;
    <span style="text-transform: capitalize;">
      post
    </span>
  </h5>
  
  <a href="/2021/05/27/pre-trained-models-as-a-strong-baseline-for-automatic-signature-verification.html" class="preview-image-holder">
    <img class="preview-image" src="/images/hugo/metricblog/feature_extraction_pretrained.png" />
  </a>
  
  <div>
    
    <a href="/2021/05/27/pre-trained-models-as-a-strong-baseline-for-automatic-signature-verification.html"
       ><h2 style="margin-bottom: 4px;">Pre-trained Models as a Strong Baseline for Automatic Signature Verification</h2></a
     >
     
  </div>
  <div class="small" style="height: 4.5em; overflow: hidden;">
    By Victor and Andrew.
Figure 1. Baseline approach for automatic signature verification using pre-trained models TLDR; This post describes how pretrained image classification models can be used as strong baselines for the task of signature verification. Other posts in the series are listed below: Pretrained Models as Baselines for Signature Verification  --   Part 1: Deep Learning for Automatic Offline Signature Verification: An Introduction    Part 2: Pretrained Models as Baselines for Signature Verification    Part 3: Deep Metric Learning for Signature Verification      As discussed in our introductory blog post, offline signature verification is a biometric verification task that aims to discriminate between genuine and forged samples of handwritten signatures.
  </div>
  <div
    style="width:100%;white-space: nowrap; overflow: hidden; text-overflow: ellipsis;"
    >
    
      <a href="/2021/05/27/pre-trained-models-as-a-strong-baseline-for-automatic-signature-verification.html">...read more</a>
    
  </div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="post-link" style="position: relative">
  <h5 style="margin-bottom: 4px;">
    <span>May 26, 2021</span> &middot;
    <span style="text-transform: capitalize;">
      post
    </span>
  </h5>
  
  <a href="/2021/05/26/deep-learning-for-automatic-offline-signature-verification-an-introduction.html" class="preview-image-holder">
    <img class="preview-image" src="/images/hugo/metricblog/signature_pipeline.png" />
  </a>
  
  <div>
    
    <a href="/2021/05/26/deep-learning-for-automatic-offline-signature-verification-an-introduction.html"
       ><h2 style="margin-bottom: 4px;">Deep Learning for Automatic Offline Signature Verification: An Introduction</h2></a
     >
     
  </div>
  <div class="small" style="height: 4.5em; overflow: hidden;">
    By Victor and Andrew.
Figure 1. A summary of tasks that comprise the automatic signature verification pipeline (and related machine learning problems). TLDR; This post provides an overview of the signature verification task, use cases, and challenges. A complete list of the posts in this series is outlined below: Pretrained Models as Baselines for Signature Verification  --   Part 1: Deep Learning for Automatic Offline Signature Verification: An Introduction    Part 2: Pretrained Models as Baselines for Signature Verification    Part 3: Deep Metric Learning for Signature Verification      Given two signatures, automatic signature verification (ASV) seeks to determine if they are produced by the same user (genuine signatures) or different users (potential forgeries).
  </div>
  <div
    style="width:100%;white-space: nowrap; overflow: hidden; text-overflow: ellipsis;"
    >
    
      <a href="/2021/05/26/deep-learning-for-automatic-offline-signature-verification-an-introduction.html">...read more</a>
    
  </div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="post-link" style="position: relative">
  <h5 style="margin-bottom: 4px;">
    <span>Nov 15, 2020</span> &middot;
    <span style="text-transform: capitalize;">
      post
    </span>
  </h5>
  
  <a href="/2020/11/15/representation-learning-101-for-software-engineers.html" class="preview-image-holder">
    <img class="preview-image" src="/images/hugo/representationlearning.png" />
  </a>
  
  <div>
    
    <a href="/2020/11/15/representation-learning-101-for-software-engineers.html"
       ><h2 style="margin-bottom: 4px;">Representation Learning 101 for Software Engineers</h2></a
     >
     
  </div>
  <div class="small" style="height: 4.5em; overflow: hidden;">
    
    <span>
      by 
      <span
        ><a href="https://twitter.com/vykthur">Victor Dibia</a>
        &middot; </span
      >
    </span>
    Figure 1: Overview of representation learning methods. TLDR; Good representations of data (e.g., text, images) are critical for solving many tasks (e.g., search or recommendations). Deep representation learning yields state of the art results when used to create these representations. In this article, we review methods for representation learning and walk through an example using pretrained models.  Introduction Deep Neural Networks (DNNs) have become a particularly useful tool in building intelligent systems that simplify cognitive tasks for users.
  </div>
  <div
    style="width:100%;white-space: nowrap; overflow: hidden; text-overflow: ellipsis;"
    >
    
      <a href="/2020/11/15/representation-learning-101-for-software-engineers.html">...read more</a>
    
  </div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="post-link" style="position: relative">
  <h5 style="margin-bottom: 4px;">
    <span>Jun 22, 2020</span> &middot;
    <span style="text-transform: capitalize;">
      post
    </span>
  </h5>
  
  <a href="/2020/06/22/how-to-explain-huggingface-bert-for-question-answering-nlp-models-with-tf-2.0.html" class="preview-image-holder">
    <img class="preview-image" src="/images/hugo/explanation-1592852095.jpg" />
  </a>
  
  <div>
    
    <a href="/2020/06/22/how-to-explain-huggingface-bert-for-question-answering-nlp-models-with-tf-2.0.html"
       ><h2 style="margin-bottom: 4px;">How to Explain HuggingFace BERT for Question Answering NLP Models with TF 2.0</h2></a
     >
     
  </div>
  <div class="small" style="height: 4.5em; overflow: hidden;">
    
    <span>
      by 
      <span
        ><a href="https://twitter.com/vykthur">Victor</a>
        &middot; </span
      >
    </span>
    Given a question and a passage, the task of Question Answering (QA) focuses on identifying the exact span within the passage that answers the question.
Figure 1: In this sample, a BERTbase model gets the answer correct (Achaemenid Persia). Model gradients show that the token &ldquo;subordinate ..&rdquo; is impactful in the selection of an answer to the question &ldquo;Macedonia was under the rule of which country?&quot;. This makes sense .. good for BERTbase.
  </div>
  <div
    style="width:100%;white-space: nowrap; overflow: hidden; text-overflow: ellipsis;"
    >
    
      <a href="/2020/06/22/how-to-explain-huggingface-bert-for-question-answering-nlp-models-with-tf-2.0.html">...read more</a>
    
  </div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="post-link" style="position: relative">
  <h5 style="margin-bottom: 4px;">
    <span>Jun 16, 2020</span> &middot;
    <span style="text-transform: capitalize;">
      notebook
    </span>
  </h5>
  
  <a href="/2020/06/16/evaluating-qa-metrics-predictions-and-the-null-response.html" class="preview-image-holder">
    <img class="preview-image" src="/images/hugo/shotwin-2020-06-16_09-31-48-1592314597.png" />
  </a>
  
  <div>
    
    <a href="https://qa.fastforwardlabs.com/no%20answer/null%20threshold/bert/distilbert/exact%20match/f1/robust%20predictions/2020/06/09/Evaluating_BERT_on_SQuAD.html" target="_blank">
      <h2 style="margin-bottom: 4px;">Evaluating QA: Metrics, Predictions, and the Null Response →</h2></a
    >
    
  </div>
  <div class="small" style="height: 4.5em; overflow: hidden;">
    
    <span>
      by 
      <span
        ><a href="https://www.linkedin.com/in/melanierbeck">Melanie</a>
        &middot; </span
      >
    </span>
    A deep dive into computing QA predictions and when to tell BERT to zip it! In our last post, Building a QA System with BERT on Wikipedia, we used the HuggingFace framework to train BERT on the SQuAD2.0 dataset and built a simple QA system on top of the Wikipedia search engine. This time, we&rsquo;ll look at how to assess the quality of a BERT-like model for Question Answering.
  </div>
  <div
    style="width:100%;white-space: nowrap; overflow: hidden; text-overflow: ellipsis;"
    >
    
      <a href="https://qa.fastforwardlabs.com/no%20answer/null%20threshold/bert/distilbert/exact%20match/f1/robust%20predictions/2020/06/09/Evaluating_BERT_on_SQuAD.html" target="_blank">
        	
        qa.fastforwardlabs.com
      </a>
    
  </div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
</div>

<div>
  <button id="load_more" style="width: 100%;">load more</button>
</div>
<div class="spacer"></div>
<div class="spacer"></div>

<script>
  window.addEventListener('load', () => {
    let $posts_holder = document.getElementById('posts-holder')
    let $load_more = document.getElementById('load_more')
    let next_page = 2
    $load_more.addEventListener('click', () => {
      fetch(`/posts/page/${next_page}.html`).then(r =>r.text()).then(r => {
        let el = document.createElement('html')
        el.innerHTML = r
        next_page += 1
        let $posts = el.querySelector('#posts-holder').children
        for (let i=0; i< $posts.length; i++) {
          let $post = $posts[i].cloneNode(true)
          $posts_holder.appendChild($post)
        }
      })
    })
  })
</script>


  <h3 class="clear">Popular posts</h3>
<div class="spacer"></div>
<div>
  
    <div>
  <h5 style="margin-bottom: 0px;">
    <span>Oct 30, 2019</span> &middot;
    <span style="text-transform: capitalize;">
      newsletter
    </span>
  </h5>
  
    <div><a href="/2019/10/30/exciting-applications-of-graph-neural-networks.html"><strong>Exciting Applications of Graph Neural Networks</strong></a></div>
  
  <div class="spacer"></div>
</div>


  
    <div>
  <h5 style="margin-bottom: 0px;">
    <span>Nov 14, 2018</span> &middot;
    <span style="text-transform: capitalize;">
      post
    </span>
  </h5>
  
    <div><a href="/2018/11/14/federated-learning-distributed-machine-learning-with-data-locality-and-privacy.html"><strong>Federated learning: distributed machine learning with data locality and privacy</strong></a></div>
  
  <div class="spacer"></div>
</div>


  
    <div>
  <h5 style="margin-bottom: 0px;">
    <span>Apr 10, 2018</span> &middot;
    <span style="text-transform: capitalize;">
      post
    </span>
  </h5>
  
    <div><a href="/2018/04/10/pytorch-for-recommenders-101.html"><strong>PyTorch for Recommenders 101</strong></a></div>
  
  <div class="spacer"></div>
</div>


  
    <div>
  <h5 style="margin-bottom: 0px;">
    <span>Oct 4, 2017</span> &middot;
    <span style="text-transform: capitalize;">
      post
    </span>
  </h5>
  
    <div><a href="/2017/10/04/first-look-using-three.js-for-2d-data-visualization.html"><strong>First Look: Using Three.js for 2D Data Visualization</strong></a></div>
  
  <div class="spacer"></div>
</div>


  
    <div>
  <h5 style="margin-bottom: 0px;">
    <span>Aug 22, 2016</span> &middot;
    <span style="text-transform: capitalize;">
      whitepaper
    </span>
  </h5>
  
    <div><a href="/2016/08/22/under-the-hood-of-the-variational-autoencoder-in-prose-and-code.html"><strong>Under the Hood of the Variational Autoencoder (in Prose and Code)</strong></a></div>
  
  <div class="spacer"></div>
</div>


  
    <div>
  <h5 style="margin-bottom: 0px;">
    <span>Feb 24, 2016</span> &middot;
    <span style="text-transform: capitalize;">
      post
    </span>
  </h5>
  
    <div><a href="/2016/02/24/hello-world-in-keras-or-scikit-learn-versus-keras.html"><strong>&#34;Hello world&#34; in Keras (or, Scikit-learn versus Keras)</strong></a></div>
  
  <div class="spacer"></div>
</div>


  
</div>

</div>

<div class="spacer"></div>
<div style="background: #efefef;">
  <div class="spacer"></div>
  <div class="spacer"></div>
  <div class="container">
  <h1 class="clear">Reports</h1>
  <div style="color: #444;">In-depth guides to specific machine learning capabilities</div>
</div>
<div class="spacer"></div>
<div style="max-width: 96ch; margin: 0 auto; padding-left: 1ch; padding-right: 1ch;">
  
    <div class="report-link" style="position: relative;">
  <h5 style="margin-bottom: 0">FF19</h5>
  <h2 style="padding-top: 0; margin-bottom: 4px;"><a href="https://session-based-recommenders.fastforwardlabs.com/" target="_blank">Session-based Recommender Systems</a></h2>
  <a class="report-image" href="https://session-based-recommenders.fastforwardlabs.com/" target="_blank" style="display: block;">
    <img style="max-width: 31ch; display: block;" src="/images/reports/ff19-cover.png" />
  </a>
  <div class="small">Being able to recommend an item of interest to a user (based on their past preferences) is a highly relevant problem in practice. A key trend over the past few years has been session-based recommendation algorithms that provide recommendations solely based on a user’s interactions in an ongoing session, and which do not require the existence of user profiles or their entire historical preferences. This report explores a simple, yet powerful, NLP-based approach (word2vec) to recommend a next item to a user. While NLP-based approaches are generally employed for linguistic tasks, here we exploit them to learn the structure induced by a user’s behavior or an item’s nature.</div>
  <div><a href="https://session-based-recommenders.fastforwardlabs.com/" target="_blank">Read the report&nbsp; →</a></div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="report-link" style="position: relative;">
  <h5 style="margin-bottom: 0">FF18</h5>
  <h2 style="padding-top: 0; margin-bottom: 4px;"><a href="https://few-shot-text-classification.fastforwardlabs.com/" target="_blank">Few-Shot Text Classification</a></h2>
  <a class="report-image" href="https://few-shot-text-classification.fastforwardlabs.com/" target="_blank" style="display: block;">
    <img style="max-width: 31ch; display: block;" src="/images/reports/ff18-combo.png" />
  </a>
  <div class="small">Text classification can be used for sentiment analysis, topic assignment, document identification, article recommendation, and more. While dozens of techniques now exist for this fundamental task, many of them require massive amounts of labeled data in order to be useful. Collecting annotations for your use case is typically one of the most costly parts of any machine learning application. In this report, we explore how latent text embeddings can be used with few (or even zero) training examples and provide insights into best practices for implementing this method.</div>
  <div><a href="https://few-shot-text-classification.fastforwardlabs.com/" target="_blank">Read the report&nbsp; →</a></div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="report-link" style="position: relative;">
  <h5 style="margin-bottom: 0">FF16</h5>
  <h2 style="padding-top: 0; margin-bottom: 4px;"><a href="https://structural-time-series.fastforwardlabs.com" target="_blank">Structural Time Series</a></h2>
  <a class="report-image" href="https://structural-time-series.fastforwardlabs.com" target="_blank" style="display: block;">
    <img style="max-width: 31ch; display: block;" src="/images/reports/ff16-combo.png" />
  </a>
  <div class="small">Time series data is ubiquitous. This report examines generalized additive models, which give us a simple, flexible, and interpretable means for modeling time series by decomposing them into structural components. We look at the benefits and trade-offs of taking a curve-fitting approach to time series, and demonstrate its use via Facebook’s Prophet library on a demand forecasting problem.</div>
  <div><a href="https://structural-time-series.fastforwardlabs.com" target="_blank">Read the report&nbsp; →</a></div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="report-link" style="position: relative;">
  <h5 style="margin-bottom: 0">FF15</h5>
  <h2 style="padding-top: 0; margin-bottom: 4px;"><a href="https://meta-learning.fastforwardlabs.com" target="_blank">Meta-Learning</a></h2>
  <a class="report-image" href="https://meta-learning.fastforwardlabs.com" target="_blank" style="display: block;">
    <img style="max-width: 31ch; display: block;" src="/images/reports/ff15-combo.png" />
  </a>
  <div class="small">In contrast to how humans learn, deep learning algorithms need vast amounts of data and compute and may yet struggle to generalize. Humans are successful in adapting quickly because they leverage their knowledge acquired from prior experience when faced with new problems. In this report, we explain how meta-learning can leverage previous knowledge acquired from data to solve novel tasks quickly and more efficiently during test time</div>
  <div><a href="https://meta-learning.fastforwardlabs.com" target="_blank">Read the report&nbsp; →</a></div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="report-link" style="position: relative;">
  <h5 style="margin-bottom: 0">FF14</h5>
  <h2 style="padding-top: 0; margin-bottom: 4px;"><a href="https://qa.fastforwardlabs.com" target="_blank">Automated Question Answering</a></h2>
  <a class="report-image" href="https://qa.fastforwardlabs.com" target="_blank" style="display: block;">
    <img style="max-width: 31ch; display: block;" src="/images/reports/ff14-combo.png" />
  </a>
  <div class="small">Automated question answering is a user-friendly way to extract information from data using natural language. Thanks to recent advances in natural language processing, question answering capabilities from unstructured text data have grown rapidly. This blog series offers a walk-through detailing the technical and practical aspects of building an end-to-end question answering system.</div>
  <div><a href="https://qa.fastforwardlabs.com" target="_blank">Read the report&nbsp; →</a></div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="report-link" style="position: relative;">
  <h5 style="margin-bottom: 0">FF13</h5>
  <h2 style="padding-top: 0; margin-bottom: 4px;"><a href="https://ff13.fastforwardlabs.com" target="_blank">Causality for Maching Learning</a></h2>
  <a class="report-image" href="https://ff13.fastforwardlabs.com" target="_blank" style="display: block;">
    <img style="max-width: 31ch; display: block;" src="/images/reports/ff13-combo.png" />
  </a>
  <div class="small">The intersection of causal inference and machine learning is a rapidly expanding area of research that&#39;s already yielding capabilities to enable building more robust, reliable, and fair machine learning systems. This report offers an introduction to causal reasoning including causal graphs and invariant prediction and how to apply causal inference tools together with classic machine learning techniques in multiple use-cases.</div>
  <div><a href="https://ff13.fastforwardlabs.com" target="_blank">Read the report&nbsp; →</a></div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="report-link" style="position: relative;">
  <h5 style="margin-bottom: 0">FF06-2020</h5>
  <h2 style="padding-top: 0; margin-bottom: 4px;"><a href="https://ff06-2020.fastforwardlabs.com" target="_blank">Interpretability</a></h2>
  <a class="report-image" href="https://ff06-2020.fastforwardlabs.com" target="_blank" style="display: block;">
    <img style="max-width: 31ch; display: block;" src="/images/reports/ff06-2020-combo.png" />
  </a>
  <div class="small">Interpretability, or the ability to explain why and how a system makes a decision, can help us improve models, satisfy regulations, and build better products. Black-box techniques like deep learning have delivered breakthrough capabilities at the cost of interpretability. In this report, recently updated to include techniques like SHAP, we show how to make models interpretable without sacrificing their capabilities or accuracy.</div>
  <div><a href="https://ff06-2020.fastforwardlabs.com" target="_blank">Read the report&nbsp; →</a></div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="report-link" style="position: relative;">
  <h5 style="margin-bottom: 0">FF12</h5>
  <h2 style="padding-top: 0; margin-bottom: 4px;"><a href="https://ff12.fastforwardlabs.com" target="_blank">Deep Learning for Anomaly Detection</a></h2>
  <a class="report-image" href="https://ff12.fastforwardlabs.com" target="_blank" style="display: block;">
    <img style="max-width: 31ch; display: block;" src="/images/reports/ff12-combo.png" />
  </a>
  <div class="small">From fraud detection to flagging abnormalities in imaging data, there are countless applications for automatic identification of abnormal data. This process can be challenging, especially when working with large, complex data. This report explores deep learning approaches (sequence models, VAEs, GANs) for anomaly detection, when to use them, performance benchmarks, and product possibilities.</div>
  <div><a href="https://ff12.fastforwardlabs.com" target="_blank">Read the report&nbsp; →</a></div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="report-link" style="position: relative;">
  <h5 style="margin-bottom: 0">FF09</h5>
  <h2 style="padding-top: 0; margin-bottom: 4px;"><a href="https://federated.fastforwardlabs.com/" target="_blank">Federated Learning</a></h2>
  <a class="report-image" href="https://federated.fastforwardlabs.com/" target="_blank" style="display: block;">
    <img style="max-width: 31ch; display: block;" src="/images/reports/ff09-combo.png" />
  </a>
  <div class="small">Federated Learning makes it possible to build machine learning systems without direct access to training data. The data remains in its original location, which helps to ensure privacy and reduces communication costs. Federated learning is a great fit for smartphones and edge hardware, healthcare and other privacy-sensitive use cases, and industrial applications such as predictive maintenance.</div>
  <div><a href="https://federated.fastforwardlabs.com/" target="_blank">Read the report&nbsp; →</a></div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="report-link" style="position: relative;">
  <h5 style="margin-bottom: 0">FF03-2019</h5>
  <h2 style="padding-top: 0; margin-bottom: 4px;"><a href="https://deep-learning-image-analysis.fastforwardlabs.com/" target="_blank">Deep Learning for Image Analysis: 2019 Edition</a></h2>
  <a class="report-image" href="https://deep-learning-image-analysis.fastforwardlabs.com/" target="_blank" style="display: block;">
    <img style="max-width: 31ch; display: block;" src="/images/reports/ff03-2019-combo.png" />
  </a>
  <div class="small">Convolutional Neural Networks (CNN) excel at learning meaningful representations of features and concepts within images. These capabilities make CNNs extremely valuable for solving problems in domains such as medical imaging, autonomous driving, manufacturing, robotics, and urban planning. In this report, we show how to select the right deep learning models for image analysis tasks and techniques for debugging deep learning models.</div>
  <div><a href="https://deep-learning-image-analysis.fastforwardlabs.com/" target="_blank">Read the report&nbsp; →</a></div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
    <div class="report-link" style="position: relative;">
  <h5 style="margin-bottom: 0">FF03</h5>
  <h2 style="padding-top: 0; margin-bottom: 4px;"><a href="https://deep-learning-image-classic.fastforwardlabs.com/" target="_blank">Deep Learning: Image Analysis</a></h2>
  <a class="report-image" href="https://deep-learning-image-classic.fastforwardlabs.com/" target="_blank" style="display: block;">
    <img style="max-width: 31ch; display: block;" src="/images/reports/ff03-classic-combo.png" />
  </a>
  <div class="small">Deep learning, or highly-connected neural networks, offers fascinating new capabilities for image analysis. Using deep learning, computers can now learn to identify objects in images. This report explores the history and current state of the field, predicts future developments, and explains how to apply deep learning today.</div>
  <div><a href="https://deep-learning-image-classic.fastforwardlabs.com/" target="_blank">Read the report&nbsp; →</a></div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
</div>


</div>

<div class="spacer"></div>
<div class="spacer"></div>
 
<div class="container">
  <h1 class="clear">Prototypes</h1>
  <div style="color: #444;">Machine learning prototypes and interactive notebooks</div>
  <div class="spacer"></div>
</div>
<div id="prototypes-holder">
  
  <div style="display: flex; flex-direction: column; position: relative; padding-left: 1ch; padding-right: 1ch; height: 360px;">
  <div>
    <h5 style="margin-bottom: 0">Library</h5>
    <h2 style="padding-top: 0; margin-bottom: 0;"><a href="https://neuralqa.fastforwardlabs.com" target="_blank">NeuralQA</a></h2>
  </div>
  <div style="flex: 1 1 auto; position: relative;">
    <a href="https://neuralqa.fastforwardlabs.com" target="_blank" style="display: block; position: absolute; top: 0.375rem; width: 100%; height: calc(100% - 0.875rem); background-image: url('/images/hugo/neuralqa-1596123511.jpg'); background-size: contain; background-position: center left; background-repeat: no-repeat;"></a>
  </div>
  <div>
    <div class="small">A usable library for question answering on large datasets.</div>
    <div style="width: 100%; white-space: nowrap; overflow: hidden; text-overflow: ellipsis;"><a href="https://neuralqa.fastforwardlabs.com" target="_blank">https://neuralqa.fastforwardlabs.com</a></div>
  </div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
  <div style="display: flex; flex-direction: column; position: relative; padding-left: 1ch; padding-right: 1ch; height: 360px;">
  <div>
    <h5 style="margin-bottom: 0">Notebook</h5>
    <h2 style="padding-top: 0; margin-bottom: 0;"><a href="https://colab.research.google.com/drive/1tTiOgJ7xvy3sjfiFC9OozbjAX1ho8WN9?usp=sharing" target="_blank">Explain BERT for Question Answering Models</a></h2>
  </div>
  <div style="flex: 1 1 auto; position: relative;">
    <a href="https://colab.research.google.com/drive/1tTiOgJ7xvy3sjfiFC9OozbjAX1ho8WN9?usp=sharing" target="_blank" style="display: block; position: absolute; top: 0.375rem; width: 100%; height: calc(100% - 0.875rem); background-image: url('/images/hugo/distilexplanation-1592852137.jpg'); background-size: contain; background-position: center left; background-repeat: no-repeat;"></a>
  </div>
  <div>
    <div class="small">Tensorflow 2.0 notebook to explain and visualize a HuggingFace BERT for Question Answering model.</div>
    <div style="width: 100%; white-space: nowrap; overflow: hidden; text-overflow: ellipsis;"><a href="https://colab.research.google.com/drive/1tTiOgJ7xvy3sjfiFC9OozbjAX1ho8WN9?usp=sharing" target="_blank">https://colab.research.google.com/drive/1tTiOgJ7xvy3sjfiFC9OozbjAX1ho8WN9?usp=sharing</a></div>
  </div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
  <div style="display: flex; flex-direction: column; position: relative; padding-left: 1ch; padding-right: 1ch; height: 360px;">
  <div>
    <h5 style="margin-bottom: 0">Notebooks</h5>
    <h2 style="padding-top: 0; margin-bottom: 0;"><a href="https://qa.fastforwardlabs.com" target="_blank">NLP for Question Answering</a></h2>
  </div>
  <div style="flex: 1 1 auto; position: relative;">
    <a href="https://qa.fastforwardlabs.com" target="_blank" style="display: block; position: absolute; top: 0.375rem; width: 100%; height: calc(100% - 0.875rem); background-image: url('/images/uploads/qa.png'); background-size: contain; background-position: center left; background-repeat: no-repeat;"></a>
  </div>
  <div>
    <div class="small">Ongoing posts and code documenting the process of building a question answering model.</div>
    <div style="width: 100%; white-space: nowrap; overflow: hidden; text-overflow: ellipsis;"><a href="https://qa.fastforwardlabs.com" target="_blank">https://qa.fastforwardlabs.com</a></div>
  </div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
  <div style="display: flex; flex-direction: column; position: relative; padding-left: 1ch; padding-right: 1ch; height: 360px;">
  <div>
    <h5 style="margin-bottom: 0">Notebook</h5>
    <h2 style="padding-top: 0; margin-bottom: 0;"><a href="https://colab.research.google.com/drive/1pjPzsw_uZew-Zcz646JTkRDhF2GkPk0N" target="_blank">Interpretability Revisited: SHAP and LIME</a></h2>
  </div>
  <div style="flex: 1 1 auto; position: relative;">
    <a href="https://colab.research.google.com/drive/1pjPzsw_uZew-Zcz646JTkRDhF2GkPk0N" target="_blank" style="display: block; position: absolute; top: 0.375rem; width: 100%; height: calc(100% - 0.875rem); background-image: url('/images/uploads/shap-and-lime.png'); background-size: contain; background-position: center left; background-repeat: no-repeat;"></a>
  </div>
  <div>
    <div class="small">Explore how to use LIME and SHAP for interpretability.</div>
    <div style="width: 100%; white-space: nowrap; overflow: hidden; text-overflow: ellipsis;"><a href="https://colab.research.google.com/drive/1pjPzsw_uZew-Zcz646JTkRDhF2GkPk0N" target="_blank">https://colab.research.google.com/drive/1pjPzsw_uZew-Zcz646JTkRDhF2GkPk0N</a></div>
  </div>
  <div class="spacer"></div>
  <div class="spacer"></div>
</div>


  
</div>
<div class="container">
  <div ><button id="load_all_prototypes" style="width: 100%;">load all</button></div>
</div>

<script>
  
  window.addEventListener('load', () => {
    let $prototypes_holder = document.getElementById('prototypes-holder')
    let $load_more = document.getElementById('load_all_prototypes')
    $load_more.addEventListener('click', () => {
      fetch(`/prototypes.html`).then(r =>r.text()).then(r => {
        $load_more.remove()
        let el = document.createElement('html')
        el.innerHTML = r
        let $posts = el.querySelector('#prototypes-holder')
        $prototypes_holder.innerHTML = $posts.innerHTML
      })
    })
  })
</script>



<div class="spacer"></div>
<div class="spacer"></div>

<div class="container">
  <div>
    <h1 class="clear">About</h1>
    <div>
      Cloudera Fast Forward is an applied machine learning reseach group.<br />
      <a
        href="https://www.cloudera.com/products/fast-forward-labs-research.html"
        >Cloudera</a
      >&nbsp;&nbsp;
      <a
        href="https://blog.fastforwardlabs.com"
        >Blog</a
      >&nbsp;&nbsp;
      <a href="https://twitter.com/fastforwardlabs">Twitter</a>
    </div>
  </div>
</div>



<div class="spacer"></div>
<div class="spacer"></div>


      </main>
 </body>
</html>
