<!DOCTYPE html>
  <html lang="en">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style type="text/css">
    body{font-family:sans-serif;font-size:16px;line-height:1.5}
    img{max-width:100%; display:block}
    h5{font-style:italic}
    blockquote{border-left:.25em solid #dfe2e5;padding:0 1em;color:#666;margin:1em 0}
    #logo{display: block; height: 1.75rem; margin-top: 20px; margin-bottom: 24px;}
  </style>
  <body>
  <div style="max-width: 660px; margin: 0 auto; padding: 0 12px 24px;">

    <div style="overflow: hidden; font-size: 14px; margin-top: 14px;">
      <div style="float: left; width: 46%;">Updates from Cloudera Fast Forward on new research, prototypes, and exciting developments</div>
        <div style="float: right; width: 46%; text-align: right;"><a href="https://blog.fastforwardlabs.com/newsletters/2022-01.html">View this email in browser</a></div>
      </div>
      <div>
      <img id="logo" src="https://blog.fastforwardlabs.com/images/cloudera-fast-forward-logo.png" />
      </div>
    <h1 id="january-2022">January 2022</h1>
<p>Welcome to the January edition of the Cloudera Fast Forward Labs newsletter.  This month we provide a glimpse of our next research topic, talk about the uniqueness of snowflakes, and share what we’ve been reading this month.</p>
<hr>
<p>It’s the start of a new year and the CFFL team is shaking off the holiday fog and ramping up with some awesome new research. While we don’t have results to share yet, we thought we could give a sneak peek at what we’re digging into — work that we’ll share more fully in the coming months!</p>
<h2 id="research-preview-text-style-transfer">Research Preview: Text Style Transfer</h2>
<p>Text style transfer (TST) is a natural language generation task with a long history in the field of natural language processing. This task has recently re-gained attention in academic circles thanks to the advancements in deep learning.  The goal of TST is to automatically <em><strong>control the style attributes</strong></em> of text while <em><strong>preserving the content</strong></em>.  Linguistic style is an important consideration for making NLP more user-centric that, historically, has been largely ignored by the colossal language models out there today. But, as humans, we know that language is <em>situational</em> — not only is the <em>context</em> of the words important, but the <em>style</em> of text itself depends heavily on the user, environment, or scenario.</p>
<p><img src="/images/hugo/tst_examples-1642805058.png" alt="Text Style Transfer examples"></p>
<p>Above are some examples of how the same content can be portrayed with different styles. The ability to automatically convert between various styles has a multitude of applications including chatbots with consistent personae (e.g., empathetic rather than emotionless), artistic writing aids, automatic text simplification, neutralizing online text, and many others.</p>
<p>Stay tuned for more on this fascinating NLP task!</p>
<h2 id="guest-blog-the-most-unique-snowflakehttpsblogclouderacomthe-most-unique-snowflake">Guest blog: <a href="https://blog.cloudera.com/the-most-unique-snowflake/">The Most Unique Snowflake</a></h2>
<p>Our fabulous colleague, Jake Bengston, is a marketing guru with the heart (and head) of a data scientist! He recently released this article on the Cloudera blog detailing how he modified one of CFFL’s applied machine learning prototypes built on the principles discussed in our <a href="https://deep-learning-image-analysis.fastforwardlabs.com/">Deep Learning for Image Analysis</a> research report. You don’t want to miss this one because it has code examples!</p>
<blockquote>
<p>Every snowflake is unique, but some must be less unique than others. In this blog we demonstrate how to repurpose an existing Applied ML Prototype (Deep Learning for Image Analysis) to create an ML model capable of finding the most unique snowflake.</p>
</blockquote>
<p><img src="/images/hugo/snowflakes-1642805048.png" alt="Snowflakes"></p>
<hr>
<h2 id="fast-forward-live">Fast Forward Live!</h2>
<p>Check out replays of livestreams covering some of our research from last year.</p>
<p><a href="https://youtu.be/7_MlFxyPYSg"><strong>Deep Learning for Automatic Offline Signature Verification</strong></a></p>
<p><a href="https://www.youtube.com/watch?v=JoRx6udpnbI"><strong>Session-based Recommender Systems</strong></a></p>
<p><a href="https://youtu.be/oLFqTj5FcEA"><strong>Few-Shot Text Classification</strong></a></p>
<p><strong><a href="https://youtu.be/o4gQLVzIm5U">Representation Learning for Software Engineers</a></strong></p>
<hr>
<h2 id="recommended-reading">Recommended reading</h2>
<p>Our research engineers share their favorite reads of the month.</p>
<p><a href="https://arxiv.org/abs/1812.03982">SlowFast Networks for Video Recognition</a></p>
<p>Studies show that some retinal cells (magnoceullular) in primates are particularly well suited for detecting fast temporal changes in the observed scene, but not spatial detail or color. Other cells (parvocellular) are the opposite and detect fine grained spatial details and color, but not fast motion. Those biological observations motivated the Slow Fast Networks (SFNs) family of architectures for video understanding. SFNs have two pathways. But in contrast with two-stream architectures that take video and optical flow as input, SFNs take only video, sampled at two different rates:</p>
<ul>
<li>The Slow pathway samples at low rate (say 2 frames per second), and, like object detectors, has layers with many channels, intended to capture mostly <em>spatial</em> semantics – the kind of <em>object</em>. It also captures slow motion by using 3D convolutions in later layers, where the field of view is large enough to capture large objects.</li>
<li>The Fast pathway samples the video at a high rate (say 16 frames per second), and is intended for capturing <em>temporal</em> semantics – the kind of <em>action</em>; it has fewer channels in order to compensate for the increased compute derived from the high frame rate.</li>
</ul>
<p>SFN achieved state-of-the-art results in 2019 and is an interesting read because of the time-versus-space insights relevant to video understanding. — <em><a href="https://uk.linkedin.com/in/daniel-valdez-balderas-9051323b">Daniel</a></em>.</p>
<p><a href="https://arxiv.org/abs/1711.07971">Non-Local Neural Networks</a></p>
<p>Non-local operations (NLOs) are introduced in this article as a means to enhance convolutional neural networks for computer vision tasks. An insightful discussion of how attention (the mechanism underlying Transformers) is but one of many possible NLOs is presented. For the specific tasks considered (video action recognition, object detection and instance segmentation), NLOs are shown to be complementary to convolutions: NLOs are particularly well suited for long-range dependencies, while convolutions are good at capturing short range interactions. Both types of operations build representations by performing weighted averages of values on a feature map. But whereas convolutions use fixed weights and are typically applied locally, the weights of NLOs depend on the feature values themselves, and are applied not only  locally but at a distance, too.</p>
<p>The proposed architectures are built by taking an image classification network (Inception), inflating some of the 2D convolutions to 3D, and inserting non-local operator blocks at different locations. The more non-local blocks, the higher the performance. Experiments show that adding more convolutions does not produce the same gains as adding non-local layers, which are therefore argued to be a crucial element in the architecture. — <em><a href="https://uk.linkedin.com/in/daniel-valdez-balderas-9051323b">Daniel</a></em>.</p>
<p><a href="https://huyenchip.com/2022/01/02/real-time-machine-learning-challenges-and-solutions.html">Real-time machine learning: challenges and solutions</a></p>
<p>Not all machine learning problems demand real-time solutions — but for those that do, its crucial to understand the challenges that stand in the way. In this article, <a href="https://huyenchip.com/">Chip Huyen</a> outlines the problem space and solution patterns that leading ML teams have adopted for online prediction and continual learning. Chip proposes an evolution of ML system maturity and breaks down the stages involved. In the end, moving from batch prediction to real-time is largely an infrastructure problem that requires organizational alignment and cooperation between the data science, platform, and engineering teams. An interesting read for anyone curious about scaling online ML systems. — <a href="https://twitter.com/andrewrreed"><em>Andrew</em></a></p>
<p><a href="https://openai.com/blog/improving-factual-accuracy/">WebGPT: Improving the factual accuracy of language models through web browsing</a></p>
<p>In this blog post, researchers from OpenAI provide a high-level overview of their recent paper on a new model called WebGPT, which has been trained to perform long-form question answering by, well, googling and citing its work! WebGPT is a GPT3-based model that is provided an open-ended question and a summary of a browser state. The model must execute <em>search</em>, <em>find in page</em>, and <em>quote</em> commands to collect passages from web pages and then synthesize that information into a long-form answer to the question, as well as cite the web pages it ultimately used.</p>
<p>Finally, a model that can do my internet surfing for me!</p>
<p>However, as the authors are keenly aware, GPT3 (and other text generating) models are prone to “hallucinating” information: generating text that, at first blush, may seem reasonable but, upon closer inspection, is neither consistent nor factually accurate. To address this the authors used human feedback to improve both the model’s helpfulness and accuracy. Additionally, human checkers also verified the model’s accuracy by determining if WebGPT’s answer was supported by <em>reliable</em> sources. But challenges remain — what determines a source’s reliability? Furthermore, the very act of providing citations can lend the model an air of authority when, in reality, WebGPT still makes basic errors.  Even with these challenges, WebGPT remains an impressive piece of engineering and an interesting blog (and paper!) to read. — <a href="https://www.linkedin.com/in/melanierbeck/"><em>Melanie</em></a></p>

  </div>


