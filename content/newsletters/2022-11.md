---
title: "CFFL November Newsletter"
date: 2022-11-15
preview_image: /images/hugo/horse_zebra_combo-1668558267.png
post_type: Newsletter
# external_url: 
---

# November 2022

Perhaps November conjures thoughts of holiday feasts and festivities, but for us, it‚Äôs the perfect time to chew the fat about machine learning! Make room on your plate for a peek behind the scenes into our current research on harnessing synthetic image generation to improve classification tasks. And, as usual, we reflect on our favorite reads of the month. 

---

## New Research!

In the first half of this year, we focused on natural language processing with our Text Style Transfer blog series. But for the past couple of months, we‚Äôve turned our attention back to topics in computer vision. Specifically, we‚Äôve been digging into how synthetic data can be used to augment imbalanced datasets for image classification and segmentation tasks. While we‚Äôre still in the midst of experimentation, we thought we‚Äôd share a peek behind the scenes at how we built and trained our own CycleGAN model. Enjoy!

### **[Implementing CycleGAN](https://blog.fastforwardlabs.com/2022/11/14/implementing-cyclegan.html)**

This post documents the first part of a research effort to quantify what (if any) performance improvement we could expect by incorporating synthetic data when training a deep neural network for detecting manufacturing defects on steel surfaces.  In order to generate the synthetic data to answer this question, we implemented CycleGAN ‚Äúfrom scratch‚Äù using PyTorch. This blog covers our initial journey of iteration and trial-and-error, where we had to answer questions like: 

- How do you set up a research problem like this?
- How can you simplify that problem into its most basic components for experimentation?
- How do you know if your ‚Äúfrom scratch‚Äù model implementation is achieving reasonable results?
- And what do zebras have to do with any of this? ü¶ì

![Where did these zebras come from?](/images/hugo/horse_zebra_combo-1668558267.png)

---

## Fast Forward Live!

Check out replays of livestreams covering some of our research from last year.

[**Deep Learning for Automatic Offline Signature Verification**](https://youtu.be/7_MlFxyPYSg)

[**Session-based Recommender Systems**](https://www.youtube.com/watch?v=JoRx6udpnbI)

[**Few-Shot Text Classification**](https://youtu.be/oLFqTj5FcEA)

**[Representation Learning for Software Engineers](https://youtu.be/o4gQLVzIm5U)**

---

## Recommended Reading

CFFLers share their favorite reads of the month.

### [A Recipe for Training Neural Networks](https://karpathy.github.io/2019/04/25/recipe/)

Who can relate ‚Äî you approach a new deep learning problem, get excited, and jump off to the races training some fancy model architecture + state-of-the-art loss function combo that you *know* will perform well because you read a blog where it worked on some ‚Äúsimilar‚Äù task? The model is training, but the results just aren‚Äôt quite what you anticipate‚Ä¶ *something* is off. If you‚Äôre lucky, an exception will be thrown. But most likely, the model trains just fine, and silently accepts the degraded performance. You‚Äôre left staring at a seemingly infinite number of possible loose ends deciding where to begin debugging‚Ä¶if you even come to realize there‚Äôs an issue at all.

As Andrej Karpathy describes, this is the beginning of the long, arduous road to suffering, and I too am guilty of marching down this ‚Äúfast and furious‚Äù path. Luckily, Andrej has compiled some excellent tidbits of knowledge into a recipe that I often reference to help steer clear of this treacherous path. His recipe calls for patience, attention to detail, and a methodical process in an effort to prevent the introduction of ‚Äúunverified complexity‚Äù which is bound to introduce bugs that take an enormous amount of time/suffering to root cause. 

I **************highly************** recommend giving this quick blog post a read and bookmarking it for any time you approach a new modeling problem. [*‚Äî Andrew*](https://twitter.com/andrewrreed)

### [Learning Semantic Segmentation From Synthetic Data: A Geometrically Guided Input-Output Adaptation Approach](https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Learning_Semantic_Segmentation_From_Synthetic_Data_A_Geometrically_Guided_Input-Output_CVPR_2019_paper.html)

Continuing the theme of synthetic data for computer vision problems, I wanted to share this paper. The authors exploit ground-truth semantic and depth information from photo-realistic simulations to train a network that jointly learns semantic segmentation and depth estimation. The method does not require ground-truth segmentation or depth maps for the real data. Instead, the training procedure adapts the network to achieve similar outputs on synthetic and real images, and also demonstrates an improvement from jointly learning the two related tasks. ‚Äî [*Mike*](https://www.linkedin.com/in/michael-gallaspy-65a492a5/)

### [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)

While the work and results within this paper are fascinating, I‚Äôm miffed by the authors‚Äô chosen title, which implies they have succeeded in training a model to ‚Äúreason.‚Äù  This is pure sensationalism, especially when considering the paper‚Äôs final paragraph in which the authors state quite plainly: 

> ‚Ä¶although chain-of-thought emulates the thought processes of human reasoners, this does not answer whether the neural network is actually ‚Äúreasoning,‚Äù which we leave as an open question.
> 

But I suppose ‚ÄúChain-of-Thought Prompting Elicits the *Emulation* of Reasoning in Large Language Models‚Äù just doesn‚Äôt have the same ring. 

Regardless, the results are intriguing! Take a gander at this example, which provides a succinct summary of the whole paper: 

![CoT Prompt example](/images/hugo/chain_of_thought_prompt-1668558308.png)

Essentially, providing a rationale as part of the language model‚Äôs input prompt encourages the model to provide a rationale of its own when answering reasoning questions, leading to far better results. The authors explore and compare chain-of-thought prompting to other methodologies on a range of arithmetic, commonsense, and symbolic reasoning tasks. This technique also lends itself well to few-shot regimes. For example, the authors find that priming a PaLM 540B model with just 8 chain-of-thought prompts surpasses a fine-tuned GPT-3+verifier on a benchmark dataset. Although the PaLM model has 3x more parameters to learn from, fine-tuning a GPT-3 model ***and*** training a verifier can be costly. The scalability of this technique could have far-reaching implications for how future language models are developed. ‚Äî [*Melanie*](https://www.linkedin.com/in/melanierbeck/)